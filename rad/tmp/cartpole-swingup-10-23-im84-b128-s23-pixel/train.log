{"episode_reward": 0.0, "episode": 1.0, "duration": 1.13746976852417, "step": 500}
{"episode_reward": 154.56731419304836, "episode": 5.0, "duration": 1.151796817779541, "step": 1000}
{"episode_reward": 186.90792292430567, "episode": 9.0, "batch_reward": 0.8563177585601807, "critic_loss": 1.6527021288871766, "actor_loss": -1.9501740694046021, "actor_target_entropy": -1.0, "actor_entropy": 0.738683557510376, "alpha_loss": 0.11643196567893029, "alpha_value": 0.09898962026273672, "duration": 8.705580711364746, "step": 1500}
{"episode_reward": 217.86625965332416, "episode": 13.0, "batch_reward": 0.9862844944000244, "critic_loss": 2.649000072479248, "actor_loss": -4.239004039764405, "actor_target_entropy": -1.0, "actor_entropy": 1.1437076926231384, "alpha_loss": 0.14059601724147797, "alpha_value": 0.09659140162169447, "duration": 8.760185956954956, "step": 2000}
{"episode_reward": 179.86871991516972, "episode": 17.0, "batch_reward": 1.0108389139175415, "critic_loss": 3.2518474102020263, "actor_loss": -6.127523612976074, "actor_target_entropy": -1.0, "actor_entropy": 1.1103659272193909, "alpha_loss": 0.12144229412078858, "alpha_value": 0.09441900791713376, "duration": 8.235966205596924, "step": 2500}
{"episode_reward": 216.5140592040314, "episode": 21.0, "batch_reward": 1.2093511819839478, "critic_loss": 4.320610046386719, "actor_loss": -9.217214965820313, "actor_target_entropy": -1.0, "actor_entropy": 0.9865115642547607, "alpha_loss": 0.07963991016149521, "alpha_value": 0.0926115473600108, "duration": 8.658219337463379, "step": 3000}
{"episode_reward": 131.8266973462976, "episode": 25.0, "batch_reward": 1.1800005435943604, "critic_loss": 7.181589794158936, "actor_loss": -12.040722465515136, "actor_target_entropy": -1.0, "actor_entropy": 0.941121518611908, "alpha_loss": 0.08429763019084931, "alpha_value": 0.09110060546644311, "duration": 8.786845445632935, "step": 3500}
{"episode_reward": 194.4290568000741, "episode": 29.0, "batch_reward": 1.1783195972442626, "critic_loss": 7.080556774139405, "actor_loss": -15.735896110534668, "actor_target_entropy": -1.0, "actor_entropy": 0.7190448403358459, "alpha_loss": 0.06747085750102996, "alpha_value": 0.08978995149032884, "duration": 9.123398065567017, "step": 4000}
{"episode_reward": 180.4964226966349, "episode": 33.0, "batch_reward": 1.096016263961792, "critic_loss": 7.370617485046386, "actor_loss": -18.79093132019043, "actor_target_entropy": -1.0, "actor_entropy": 0.6463061213493347, "alpha_loss": 0.035656248778104783, "alpha_value": 0.0889258313306664, "duration": 8.306232452392578, "step": 4500}
{"episode_reward": 140.22717446365948, "episode": 37.0, "batch_reward": 1.275367021560669, "critic_loss": 8.282161045074464, "actor_loss": -22.923948669433592, "actor_target_entropy": -1.0, "actor_entropy": 0.5690650343894958, "alpha_loss": 0.010616276459768415, "alpha_value": 0.0884151307880146, "duration": 8.355703830718994, "step": 5000}
{"episode_reward": 268.1350819587464, "episode": 41.0, "batch_reward": 1.2248817205429077, "critic_loss": 5.605399036407471, "actor_loss": -26.7958251953125, "actor_target_entropy": -1.0, "actor_entropy": 0.4677751958370209, "alpha_loss": -0.0025786060839891435, "alpha_value": 0.0882089316783634, "duration": 8.298502683639526, "step": 5500}
{"episode_reward": 183.3879479587093, "episode": 45.0, "batch_reward": 1.304499125480652, "critic_loss": 7.0346424102783205, "actor_loss": -31.079602432250976, "actor_target_entropy": -1.0, "actor_entropy": 0.4922103762626648, "alpha_loss": -0.004311603307723999, "alpha_value": 0.08819583506008546, "duration": 7.869896650314331, "step": 6000}
{"episode_reward": 172.44366439749564, "episode": 49.0, "batch_reward": 1.2704633235931397, "critic_loss": 6.423975992202759, "actor_loss": -35.138946533203125, "actor_target_entropy": -1.0, "actor_entropy": 0.4820996105670929, "alpha_loss": -0.01313169258646667, "alpha_value": 0.08849110686042247, "duration": 7.621613025665283, "step": 6500}
{"episode_reward": 323.1178399332534, "episode": 53.0, "batch_reward": 1.3134900093078614, "critic_loss": 8.329341411590576, "actor_loss": -38.88345642089844, "actor_target_entropy": -1.0, "actor_entropy": 0.39151317477226255, "alpha_loss": -0.012109932629391551, "alpha_value": 0.08866983144334344, "duration": 8.276246547698975, "step": 7000}
{"episode_reward": 178.28014491623486, "episode": 57.0, "batch_reward": 1.3641465425491333, "critic_loss": 9.750591373443603, "actor_loss": -42.77720947265625, "actor_target_entropy": -1.0, "actor_entropy": 0.37912302017211913, "alpha_loss": -0.001547795720398426, "alpha_value": 0.08884914909713756, "duration": 8.362399816513062, "step": 7500}
{"episode_reward": 211.8399797360364, "episode": 61.0, "batch_reward": 1.4145039796829224, "critic_loss": 15.752673149108887, "actor_loss": -46.88688659667969, "actor_target_entropy": -1.0, "actor_entropy": 0.4055613040924072, "alpha_loss": -0.0017198936082422733, "alpha_value": 0.0891801223698359, "duration": 7.788717269897461, "step": 8000}
{"episode_reward": 228.92483602690797, "episode": 65.0, "batch_reward": 1.4753438234329224, "critic_loss": 7.933166599273681, "actor_loss": -50.02422409057617, "actor_target_entropy": -1.0, "actor_entropy": 0.4484298825263977, "alpha_loss": -0.010744929593056441, "alpha_value": 0.08968934730461886, "duration": 8.858274459838867, "step": 8500}
{"episode_reward": 161.33976384635483, "episode": 69.0, "batch_reward": 1.4874162435531617, "critic_loss": 10.470103454589843, "actor_loss": -54.16552810668945, "actor_target_entropy": -1.0, "actor_entropy": 0.3670375347137451, "alpha_loss": -0.01060614907182753, "alpha_value": 0.09060431547054673, "duration": 7.95607590675354, "step": 9000}
{"episode_reward": 227.0577937415751, "episode": 73.0, "batch_reward": 1.4430172204971314, "critic_loss": 10.655039978027343, "actor_loss": -57.756185913085936, "actor_target_entropy": -1.0, "actor_entropy": 0.4008246064186096, "alpha_loss": -0.01343220453709364, "alpha_value": 0.09204424250550049, "duration": 9.248341083526611, "step": 9500}
{"episode_reward": 268.6682493783339, "episode": 77.0, "batch_reward": 1.5332711219787598, "critic_loss": 15.323593521118164, "actor_loss": -60.619896697998044, "actor_target_entropy": -1.0, "actor_entropy": 0.4831540107727051, "alpha_loss": -0.026810352876782417, "alpha_value": 0.09394736142239361, "step": 10000}
{"duration": 25.34390115737915, "step": 10000}
{"episode_reward": 250.14752434080515, "episode": 81.0, "batch_reward": 1.439602828025818, "critic_loss": 12.580535316467286, "actor_loss": -63.7507209777832, "actor_target_entropy": -1.0, "actor_entropy": 0.41468251347541807, "alpha_loss": -0.03297853581607342, "alpha_value": 0.09601021283614672, "duration": 8.425637483596802, "step": 10500}
{"episode_reward": 212.49957022854494, "episode": 85.0, "batch_reward": 1.589297342300415, "critic_loss": 10.53439121246338, "actor_loss": -68.25299224853515, "actor_target_entropy": -1.0, "actor_entropy": 0.38104785680770875, "alpha_loss": -0.031890228018164636, "alpha_value": 0.09824891137074507, "duration": 8.386029958724976, "step": 11000}
{"episode_reward": 235.9697149595122, "episode": 89.0, "batch_reward": 1.5908329248428346, "critic_loss": 15.279602813720704, "actor_loss": -72.08413391113281, "actor_target_entropy": -1.0, "actor_entropy": 0.39338738918304444, "alpha_loss": -0.02511761267669499, "alpha_value": 0.10033291455635127, "duration": 7.477553367614746, "step": 11500}
{"episode_reward": 206.56700061157827, "episode": 93.0, "batch_reward": 1.5954010248184205, "critic_loss": 15.779196548461915, "actor_loss": -75.19329071044922, "actor_target_entropy": -1.0, "actor_entropy": 0.35578837990760803, "alpha_loss": -0.034770186990499496, "alpha_value": 0.10248347108787041, "duration": 7.632241249084473, "step": 12000}
{"episode_reward": 172.15911818107045, "episode": 97.0, "batch_reward": 1.5222191095352173, "critic_loss": 15.7757719039917, "actor_loss": -77.36854095458985, "actor_target_entropy": -1.0, "actor_entropy": 0.39769430458545685, "alpha_loss": -0.02754070293158293, "alpha_value": 0.10449323943651379, "duration": 8.994549989700317, "step": 12500}
{"episode_reward": 117.45286159549256, "episode": 101.0, "batch_reward": 1.4999269008636475, "critic_loss": 17.990954303741454, "actor_loss": -81.56730194091797, "actor_target_entropy": -1.0, "actor_entropy": 0.3137567132711411, "alpha_loss": -0.018320813402533533, "alpha_value": 0.10648533246229967, "duration": 7.127567768096924, "step": 13000}
{"episode_reward": 247.807580215211, "episode": 105.0, "batch_reward": 1.5368339776992799, "critic_loss": 19.895570945739745, "actor_loss": -84.89775695800782, "actor_target_entropy": -1.0, "actor_entropy": 0.42577224373817446, "alpha_loss": -0.022341261617839336, "alpha_value": 0.10854478677218964, "duration": 8.861076593399048, "step": 13500}
{"episode_reward": 336.41020051675684, "episode": 109.0, "batch_reward": 1.5070659160614013, "critic_loss": 18.2238712310791, "actor_loss": -87.6110824584961, "actor_target_entropy": -1.0, "actor_entropy": 0.36964457035064696, "alpha_loss": -0.014883721433579921, "alpha_value": 0.11045292916871893, "duration": 7.557403326034546, "step": 14000}
{"episode_reward": 241.30621694178998, "episode": 113.0, "batch_reward": 1.5170297145843505, "critic_loss": 18.72666988372803, "actor_loss": -90.7241928100586, "actor_target_entropy": -1.0, "actor_entropy": 0.3555755436420441, "alpha_loss": -0.016410453245043755, "alpha_value": 0.11235239200518447, "duration": 7.1559271812438965, "step": 14500}
{"episode_reward": 172.68683680588205, "episode": 117.0, "batch_reward": 1.58481023311615, "critic_loss": 22.56020317077637, "actor_loss": -94.16374969482422, "actor_target_entropy": -1.0, "actor_entropy": 0.2772922098636627, "alpha_loss": -0.013416603300720453, "alpha_value": 0.11436137418237331, "duration": 7.153079509735107, "step": 15000}
{"episode_reward": 188.33861450661195, "episode": 121.0, "batch_reward": 1.4940300703048706, "critic_loss": 19.081432723999022, "actor_loss": -96.2265838623047, "actor_target_entropy": -1.0, "actor_entropy": 0.31447971761226656, "alpha_loss": -0.021869420632719995, "alpha_value": 0.11623894105765897, "duration": 7.182010889053345, "step": 15500}
{"episode_reward": 222.39955887972835, "episode": 125.0, "batch_reward": 1.5359220504760742, "critic_loss": 27.23598289489746, "actor_loss": -100.12799987792968, "actor_target_entropy": -1.0, "actor_entropy": 0.2416676640510559, "alpha_loss": -0.006318361731246114, "alpha_value": 0.11806036821695547, "duration": 9.305520057678223, "step": 16000}
{"episode_reward": 178.55466984393445, "episode": 129.0, "batch_reward": 1.541167187690735, "critic_loss": 42.33770484924317, "actor_loss": -103.19111938476563, "actor_target_entropy": -1.0, "actor_entropy": 0.2021026536822319, "alpha_loss": -0.013902131514623762, "alpha_value": 0.11963419136756141, "duration": 9.356061935424805, "step": 16500}
{"episode_reward": 243.02960169367162, "episode": 133.0, "batch_reward": 1.5539594650268556, "critic_loss": 24.85175838470459, "actor_loss": -107.01910552978515, "actor_target_entropy": -1.0, "actor_entropy": 0.17488572895526885, "alpha_loss": -0.019608833827078342, "alpha_value": 0.12106239150437577, "duration": 10.308122873306274, "step": 17000}
{"episode_reward": 172.0005493981701, "episode": 137.0, "batch_reward": 1.5573461055755615, "critic_loss": 19.79345703125, "actor_loss": -109.58424072265625, "actor_target_entropy": -1.0, "actor_entropy": 0.17424237430095674, "alpha_loss": -0.009424979193136096, "alpha_value": 0.12259075856606752, "duration": 9.445878744125366, "step": 17500}
{"episode_reward": 207.6482967053768, "episode": 141.0, "batch_reward": 1.6663643836975097, "critic_loss": 24.216593170166014, "actor_loss": -112.90795593261718, "actor_target_entropy": -1.0, "actor_entropy": 0.28018154203891754, "alpha_loss": -0.014789307676255702, "alpha_value": 0.12446167562703099, "duration": 7.779754877090454, "step": 18000}
{"episode_reward": 187.84552041036764, "episode": 145.0, "batch_reward": 1.5441835880279542, "critic_loss": 21.038271713256837, "actor_loss": -115.85559997558593, "actor_target_entropy": -1.0, "actor_entropy": 0.11700441762804985, "alpha_loss": -0.006930822879076004, "alpha_value": 0.12637272093174107, "duration": 8.051299095153809, "step": 18500}
{"episode_reward": 176.75989315338984, "episode": 149.0, "batch_reward": 1.6205992937088012, "critic_loss": 20.870206832885742, "actor_loss": -118.49907531738282, "actor_target_entropy": -1.0, "actor_entropy": 0.2003074750304222, "alpha_loss": -0.01730435062199831, "alpha_value": 0.1282282971346679, "duration": 9.07158350944519, "step": 19000}
{"episode_reward": 200.32865523568032, "episode": 153.0, "batch_reward": 1.5343946933746337, "critic_loss": 23.572773742675782, "actor_loss": -121.92312469482422, "actor_target_entropy": -1.0, "actor_entropy": 0.2799941420555115, "alpha_loss": -0.017735673859715462, "alpha_value": 0.1300408723416278, "duration": 8.698832035064697, "step": 19500}
{"episode_reward": 288.3178143663308, "episode": 157.0, "batch_reward": 1.5458310842514038, "critic_loss": 16.821079826354982, "actor_loss": -123.84350280761718, "actor_target_entropy": -1.0, "actor_entropy": 0.31225130558013914, "alpha_loss": -0.011490829940885305, "alpha_value": 0.13121642690916235, "step": 20000}
{"duration": 26.35538148880005, "step": 20000}
{"episode_reward": 182.371195249638, "episode": 161.0, "batch_reward": 1.6699283838272094, "critic_loss": 21.595355224609374, "actor_loss": -126.25234680175781, "actor_target_entropy": -1.0, "actor_entropy": 0.19658673107624053, "alpha_loss": -0.0038079794496297835, "alpha_value": 0.13244547235719986, "duration": 7.940464496612549, "step": 20500}
{"episode_reward": 150.48888291949882, "episode": 165.0, "batch_reward": 1.5663756370544433, "critic_loss": 18.856576919555664, "actor_loss": -128.89268798828124, "actor_target_entropy": -1.0, "actor_entropy": 0.24207885563373566, "alpha_loss": -0.016638998687267304, "alpha_value": 0.13393464395712812, "duration": 7.7150633335113525, "step": 21000}
{"episode_reward": 187.46502404612508, "episode": 169.0, "batch_reward": 1.5201605319976808, "critic_loss": 14.498553848266601, "actor_loss": -130.5000762939453, "actor_target_entropy": -1.0, "actor_entropy": 0.29597259163856504, "alpha_loss": 0.0021242793649435044, "alpha_value": 0.13551677851593288, "duration": 8.601582288742065, "step": 21500}
{"episode_reward": 189.66917199743693, "episode": 173.0, "batch_reward": 1.6903944730758667, "critic_loss": 21.200114822387697, "actor_loss": -133.15646057128907, "actor_target_entropy": -1.0, "actor_entropy": 0.2537909746170044, "alpha_loss": -0.004533835221081972, "alpha_value": 0.13570119675475337, "duration": 9.639256954193115, "step": 22000}
{"episode_reward": 328.0235562221496, "episode": 177.0, "batch_reward": 1.688229489326477, "critic_loss": 17.36222267150879, "actor_loss": -135.49550170898436, "actor_target_entropy": -1.0, "actor_entropy": 0.26207832992076874, "alpha_loss": -0.005697490274906158, "alpha_value": 0.13642287884063417, "duration": 8.39132571220398, "step": 22500}
{"episode_reward": 229.57859003345177, "episode": 181.0, "batch_reward": 1.6459082126617433, "critic_loss": 24.514066314697267, "actor_loss": -138.03663024902343, "actor_target_entropy": -1.0, "actor_entropy": 0.17770299911499024, "alpha_loss": -0.011616293154656888, "alpha_value": 0.13707637897579522, "duration": 7.5489537715911865, "step": 23000}
{"episode_reward": 260.6071707602179, "episode": 185.0, "batch_reward": 1.4512098550796508, "critic_loss": 18.11047248840332, "actor_loss": -139.65862121582032, "actor_target_entropy": -1.0, "actor_entropy": 0.30110029578208924, "alpha_loss": -0.011736119585111737, "alpha_value": 0.13820166145367135, "duration": 8.183982849121094, "step": 23500}
{"episode_reward": 203.0895247801769, "episode": 189.0, "batch_reward": 1.7855653524398805, "critic_loss": 19.879404067993164, "actor_loss": -143.00760803222656, "actor_target_entropy": -1.0, "actor_entropy": 0.22794555723667145, "alpha_loss": -0.00044653061777353285, "alpha_value": 0.1398904091577255, "duration": 10.167410612106323, "step": 24000}
{"episode_reward": 189.2201261629726, "episode": 193.0, "batch_reward": 1.7636863231658935, "critic_loss": 15.33122215270996, "actor_loss": -144.80221252441407, "actor_target_entropy": -1.0, "actor_entropy": 0.21241616010665892, "alpha_loss": 0.004955644859001041, "alpha_value": 0.1409101301122611, "duration": 8.43924617767334, "step": 24500}
{"episode_reward": 219.52460743669107, "episode": 197.0, "batch_reward": 1.6294069051742555, "critic_loss": 20.450802040100097, "actor_loss": -145.91680603027345, "actor_target_entropy": -1.0, "actor_entropy": 0.27172168493270876, "alpha_loss": -0.015664841700345277, "alpha_value": 0.1422169547865359, "duration": 7.74981427192688, "step": 25000}
{"episode_reward": 316.4343925881204, "episode": 201.0, "batch_reward": 1.7055001497268676, "critic_loss": 18.882871627807617, "actor_loss": -148.85013122558593, "actor_target_entropy": -1.0, "actor_entropy": 0.2665286213159561, "alpha_loss": -0.023308565467596055, "alpha_value": 0.1444171367223988, "duration": 7.470236301422119, "step": 25500}
{"episode_reward": 279.7712754685895, "episode": 205.0, "batch_reward": 1.6651719570159913, "critic_loss": 17.71666259765625, "actor_loss": -150.64667663574218, "actor_target_entropy": -1.0, "actor_entropy": 0.26390023827552794, "alpha_loss": -0.013604786712676287, "alpha_value": 0.14618437794380096, "duration": 7.086451292037964, "step": 26000}
{"episode_reward": 297.3099250131633, "episode": 209.0, "batch_reward": 1.6248232126235962, "critic_loss": 28.550839996337892, "actor_loss": -153.15708618164064, "actor_target_entropy": -1.0, "actor_entropy": 0.32678396105766294, "alpha_loss": -0.020862580090761185, "alpha_value": 0.14762078356712469, "duration": 7.181119918823242, "step": 26500}
{"episode_reward": 154.8956232423582, "episode": 213.0, "batch_reward": 1.618800115585327, "critic_loss": 15.784363937377929, "actor_loss": -154.00609741210937, "actor_target_entropy": -1.0, "actor_entropy": 0.3504831075668335, "alpha_loss": -0.010090288519859315, "alpha_value": 0.14992571116244072, "duration": 8.412700414657593, "step": 27000}
{"episode_reward": 273.99335413852447, "episode": 217.0, "batch_reward": 1.7399181604385376, "critic_loss": 26.52132568359375, "actor_loss": -156.11812438964844, "actor_target_entropy": -1.0, "actor_entropy": 0.3265847533941269, "alpha_loss": -0.010701274778693915, "alpha_value": 0.1516365502356439, "duration": 8.194332599639893, "step": 27500}
{"episode_reward": 334.5295407144851, "episode": 221.0, "batch_reward": 1.6861388444900514, "critic_loss": 19.32094841003418, "actor_loss": -158.12581787109374, "actor_target_entropy": -1.0, "actor_entropy": 0.3639938235282898, "alpha_loss": -0.007742340490221977, "alpha_value": 0.15378221020014188, "duration": 8.885227918624878, "step": 28000}
{"episode_reward": 281.9854189081176, "episode": 225.0, "batch_reward": 1.5947081565856933, "critic_loss": 28.95619430541992, "actor_loss": -159.834716796875, "actor_target_entropy": -1.0, "actor_entropy": 0.32439069747924804, "alpha_loss": -0.038670158758759496, "alpha_value": 0.15612265066115194, "duration": 8.022516250610352, "step": 28500}
{"episode_reward": 205.5723528696828, "episode": 229.0, "batch_reward": 1.6330774545669555, "critic_loss": 18.938469696044923, "actor_loss": -160.1848358154297, "actor_target_entropy": -1.0, "actor_entropy": 0.4149042308330536, "alpha_loss": -0.01428531128913164, "alpha_value": 0.15852018419217856, "duration": 7.849406957626343, "step": 29000}
{"episode_reward": 182.1553123973582, "episode": 233.0, "batch_reward": 1.695121693611145, "critic_loss": 16.48921146392822, "actor_loss": -162.76112670898436, "actor_target_entropy": -1.0, "actor_entropy": 0.41656936407089235, "alpha_loss": 0.006434674561023712, "alpha_value": 0.1592892193509519, "duration": 10.167282581329346, "step": 29500}
{"episode_reward": 208.77757011990383, "episode": 237.0, "batch_reward": 1.5593149662017822, "critic_loss": 28.434719848632813, "actor_loss": -163.15755615234374, "actor_target_entropy": -1.0, "actor_entropy": 0.3695473074913025, "alpha_loss": 0.002832876332104206, "alpha_value": 0.1594696210902888, "step": 30000}
{"duration": 25.86841082572937, "step": 30000}
{"episode_reward": 236.6851059646009, "episode": 241.0, "batch_reward": 1.6159553527832031, "critic_loss": 21.40663070678711, "actor_loss": -166.58233337402345, "actor_target_entropy": -1.0, "actor_entropy": 0.4014315068721771, "alpha_loss": -0.006421323679387569, "alpha_value": 0.16075869376096955, "duration": 9.358535528182983, "step": 30500}
{"episode_reward": 220.10305202740716, "episode": 245.0, "batch_reward": 1.6753968477249146, "critic_loss": 21.31507740020752, "actor_loss": -167.88302612304688, "actor_target_entropy": -1.0, "actor_entropy": 0.3524248778820038, "alpha_loss": -0.016802378930151463, "alpha_value": 0.161713415502171, "duration": 7.686243057250977, "step": 31000}
{"episode_reward": 287.0477990051945, "episode": 249.0, "batch_reward": 1.639428400993347, "critic_loss": 20.77943687438965, "actor_loss": -168.6179412841797, "actor_target_entropy": -1.0, "actor_entropy": 0.3588749051094055, "alpha_loss": -0.0031289802864193916, "alpha_value": 0.1627999110901498, "duration": 8.322896480560303, "step": 31500}
{"episode_reward": 242.29285688226383, "episode": 253.0, "batch_reward": 1.6419490575790405, "critic_loss": 18.98927421569824, "actor_loss": -170.1955322265625, "actor_target_entropy": -1.0, "actor_entropy": 0.3981435626745224, "alpha_loss": -0.03660965126473457, "alpha_value": 0.16418621688688453, "duration": 7.9763548374176025, "step": 32000}
{"episode_reward": 318.5930413423355, "episode": 257.0, "batch_reward": 1.6889581680297852, "critic_loss": 19.741888809204102, "actor_loss": -171.78518676757812, "actor_target_entropy": -1.0, "actor_entropy": 0.447942191362381, "alpha_loss": -0.002912643039599061, "alpha_value": 0.16603221325020992, "duration": 8.231998443603516, "step": 32500}
{"episode_reward": 213.94249588348038, "episode": 261.0, "batch_reward": 1.6919610977172852, "critic_loss": 25.38116340637207, "actor_loss": -174.4037872314453, "actor_target_entropy": -1.0, "actor_entropy": 0.3971186876296997, "alpha_loss": 0.002774161845445633, "alpha_value": 0.1670852343657201, "duration": 8.52310848236084, "step": 33000}
{"episode_reward": 156.2104460412183, "episode": 265.0, "batch_reward": 1.6397432327270507, "critic_loss": 19.947212982177735, "actor_loss": -175.24921569824218, "actor_target_entropy": -1.0, "actor_entropy": 0.40426156520843504, "alpha_loss": -0.007441025227308273, "alpha_value": 0.16730527474850496, "duration": 7.426010847091675, "step": 33500}
{"episode_reward": 230.80482937811882, "episode": 269.0, "batch_reward": 1.6260802745819092, "critic_loss": 17.49651470184326, "actor_loss": -175.7853759765625, "actor_target_entropy": -1.0, "actor_entropy": 0.38616796731948855, "alpha_loss": -0.00011208523064851761, "alpha_value": 0.16746939018403, "duration": 9.931854248046875, "step": 34000}
{"episode_reward": 279.9909411316982, "episode": 273.0, "batch_reward": 1.8260649681091308, "critic_loss": 31.096474838256835, "actor_loss": -179.43988037109375, "actor_target_entropy": -1.0, "actor_entropy": 0.32965355813503266, "alpha_loss": -0.0026843806728720663, "alpha_value": 0.16803206858676498, "duration": 8.172736883163452, "step": 34500}
{"episode_reward": 213.0203859324264, "episode": 277.0, "batch_reward": 1.7283079385757447, "critic_loss": 24.331457138061523, "actor_loss": -179.48519897460938, "actor_target_entropy": -1.0, "actor_entropy": 0.393837708234787, "alpha_loss": -0.013116534799337387, "alpha_value": 0.1685865752814591, "duration": 8.300717830657959, "step": 35000}
{"episode_reward": 241.179427149556, "episode": 281.0, "batch_reward": 1.7684359073638916, "critic_loss": 20.01490592956543, "actor_loss": -181.47876586914063, "actor_target_entropy": -1.0, "actor_entropy": 0.3851305067539215, "alpha_loss": -0.020774054899811746, "alpha_value": 0.16888892725240284, "duration": 9.090384006500244, "step": 35500}
{"episode_reward": 217.38805367668115, "episode": 285.0, "batch_reward": 1.7045133352279662, "critic_loss": 19.66776885986328, "actor_loss": -181.5125274658203, "actor_target_entropy": -1.0, "actor_entropy": 0.3906159818172455, "alpha_loss": -0.004671347513794899, "alpha_value": 0.1702165424055727, "duration": 7.716833114624023, "step": 36000}
{"episode_reward": 217.90421232371085, "episode": 289.0, "batch_reward": 1.6134182929992675, "critic_loss": 22.30354881286621, "actor_loss": -181.40381469726563, "actor_target_entropy": -1.0, "actor_entropy": 0.47049298882484436, "alpha_loss": -0.018714512512087823, "alpha_value": 0.17096514910982435, "duration": 7.394702672958374, "step": 36500}
{"episode_reward": 247.35824291437183, "episode": 293.0, "batch_reward": 1.68429536819458, "critic_loss": 19.631153106689453, "actor_loss": -184.09554138183594, "actor_target_entropy": -1.0, "actor_entropy": 0.3030975520610809, "alpha_loss": -0.006894380226731301, "alpha_value": 0.17217217388635467, "duration": 8.670350551605225, "step": 37000}
{"episode_reward": 192.84120714902477, "episode": 297.0, "batch_reward": 1.6654903411865234, "critic_loss": 25.51140441894531, "actor_loss": -185.36157836914063, "actor_target_entropy": -1.0, "actor_entropy": 0.40859084129333495, "alpha_loss": 0.007248300593346357, "alpha_value": 0.17354857305015747, "duration": 8.854402303695679, "step": 37500}
{"episode_reward": 177.0006085813394, "episode": 301.0, "batch_reward": 1.7284457206726074, "critic_loss": 20.84729995727539, "actor_loss": -186.55736083984374, "actor_target_entropy": -1.0, "actor_entropy": 0.3371653378009796, "alpha_loss": -0.004183356836438179, "alpha_value": 0.17491089281934022, "duration": 8.013888597488403, "step": 38000}
{"episode_reward": 239.7899906837581, "episode": 305.0, "batch_reward": 1.7093419313430787, "critic_loss": 23.57926826477051, "actor_loss": -188.85767211914063, "actor_target_entropy": -1.0, "actor_entropy": 0.3748557507991791, "alpha_loss": 0.012884511426091195, "alpha_value": 0.17550861985166133, "duration": 7.895051002502441, "step": 38500}
{"episode_reward": 252.85080094099322, "episode": 309.0, "batch_reward": 1.682992696762085, "critic_loss": 18.1144229888916, "actor_loss": -188.86749572753905, "actor_target_entropy": -1.0, "actor_entropy": 0.3668167471885681, "alpha_loss": 0.003224659711122513, "alpha_value": 0.17589229494775024, "duration": 7.9703943729400635, "step": 39000}
{"episode_reward": 266.5669977599097, "episode": 313.0, "batch_reward": 1.69135525226593, "critic_loss": 25.688544082641602, "actor_loss": -190.2779541015625, "actor_target_entropy": -1.0, "actor_entropy": 0.4172625422477722, "alpha_loss": 0.0004973258823156357, "alpha_value": 0.17603597310361577, "duration": 8.80238962173462, "step": 39500}
{"episode_reward": 217.42756095697197, "episode": 317.0, "batch_reward": 1.7370804309844972, "critic_loss": 23.47238998413086, "actor_loss": -190.8318328857422, "actor_target_entropy": -1.0, "actor_entropy": 0.3798807680606842, "alpha_loss": -0.012101342156529426, "alpha_value": 0.1766810388658922, "step": 40000}
{"duration": 26.300944089889526, "step": 40000}
{"episode_reward": 286.1082514734321, "episode": 321.0, "batch_reward": 1.8174391031265258, "critic_loss": 25.779712677001953, "actor_loss": -192.8649932861328, "actor_target_entropy": -1.0, "actor_entropy": 0.35888356566429136, "alpha_loss": 0.006385242193937301, "alpha_value": 0.17779558141998691, "duration": 7.897150993347168, "step": 40500}
{"episode_reward": 262.11045114598795, "episode": 325.0, "batch_reward": 1.717151117324829, "critic_loss": 25.148198318481445, "actor_loss": -193.6863525390625, "actor_target_entropy": -1.0, "actor_entropy": 0.4348967492580414, "alpha_loss": -0.019269946962594986, "alpha_value": 0.17957812300485626, "duration": 7.508214712142944, "step": 41000}
{"episode_reward": 234.40146807540523, "episode": 329.0, "batch_reward": 1.7645092010498047, "critic_loss": 25.7478271484375, "actor_loss": -195.40167236328125, "actor_target_entropy": -1.0, "actor_entropy": 0.4077255427837372, "alpha_loss": 0.013061848655343055, "alpha_value": 0.18002657223641916, "duration": 8.304884910583496, "step": 41500}
{"episode_reward": 189.46629482238043, "episode": 333.0, "batch_reward": 1.5759483098983764, "critic_loss": 26.080296325683594, "actor_loss": -193.96034240722656, "actor_target_entropy": -1.0, "actor_entropy": 0.3398293569684029, "alpha_loss": -0.029885605350136756, "alpha_value": 0.1798732061340989, "duration": 8.709458351135254, "step": 42000}
{"episode_reward": 181.19485125690375, "episode": 337.0, "batch_reward": 1.8122056245803833, "critic_loss": 19.496960830688476, "actor_loss": -196.36028442382812, "actor_target_entropy": -1.0, "actor_entropy": 0.35742280781269076, "alpha_loss": 0.00555260106921196, "alpha_value": 0.17878787670511237, "duration": 7.9039225578308105, "step": 42500}
{"episode_reward": 205.24914747943495, "episode": 341.0, "batch_reward": 1.7285707950592042, "critic_loss": 22.61174659729004, "actor_loss": -196.63538513183593, "actor_target_entropy": -1.0, "actor_entropy": 0.372915643453598, "alpha_loss": -0.03701535761356354, "alpha_value": 0.17853925580867758, "duration": 8.774652004241943, "step": 43000}
{"episode_reward": 255.82350264734094, "episode": 345.0, "batch_reward": 1.7018956661224365, "critic_loss": 25.962874984741212, "actor_loss": -197.29160766601564, "actor_target_entropy": -1.0, "actor_entropy": 0.36286466121673583, "alpha_loss": -0.022073719836771487, "alpha_value": 0.17920487316316108, "duration": 7.714808225631714, "step": 43500}
{"episode_reward": 189.01654192245513, "episode": 349.0, "batch_reward": 1.7510715484619142, "critic_loss": 20.39476146697998, "actor_loss": -198.6763488769531, "actor_target_entropy": -1.0, "actor_entropy": 0.322412770986557, "alpha_loss": 0.013448580540716648, "alpha_value": 0.17959527016515803, "duration": 7.588104724884033, "step": 44000}
{"episode_reward": 186.40134064156172, "episode": 353.0, "batch_reward": 1.7613041877746582, "critic_loss": 17.694948577880858, "actor_loss": -199.73918762207032, "actor_target_entropy": -1.0, "actor_entropy": 0.3190764605998993, "alpha_loss": -0.0037694094702601434, "alpha_value": 0.17943514826099705, "duration": 7.324371337890625, "step": 44500}
{"episode_reward": 297.3919006545657, "episode": 357.0, "batch_reward": 1.8112112283706665, "critic_loss": 27.39559860229492, "actor_loss": -199.97120666503906, "actor_target_entropy": -1.0, "actor_entropy": 0.32013640403747556, "alpha_loss": -0.0018867850303649902, "alpha_value": 0.17959694371723786, "duration": 7.095498323440552, "step": 45000}
{"episode_reward": 425.988169286531, "episode": 361.0, "batch_reward": 1.6344950675964356, "critic_loss": 27.430229568481444, "actor_loss": -200.99871826171875, "actor_target_entropy": -1.0, "actor_entropy": 0.3125454246997833, "alpha_loss": 0.01290425956249237, "alpha_value": 0.17992033325365128, "duration": 7.110290288925171, "step": 45500}
{"episode_reward": 256.35525272521346, "episode": 365.0, "batch_reward": 1.7348324060440063, "critic_loss": 24.167537689208984, "actor_loss": -201.322900390625, "actor_target_entropy": -1.0, "actor_entropy": 0.30293646454811096, "alpha_loss": -0.01049061338417232, "alpha_value": 0.18026205317166905, "duration": 7.1330602169036865, "step": 46000}
{"episode_reward": 204.4751885580598, "episode": 369.0, "batch_reward": 1.735823392868042, "critic_loss": 20.077199935913086, "actor_loss": -202.88388671875, "actor_target_entropy": -1.0, "actor_entropy": 0.30884324908256533, "alpha_loss": -0.006732786260545254, "alpha_value": 0.18117468310901694, "duration": 7.102959871292114, "step": 46500}
{"episode_reward": 219.20090391465163, "episode": 373.0, "batch_reward": 1.7268097400665283, "critic_loss": 19.87326374053955, "actor_loss": -203.64351501464844, "actor_target_entropy": -1.0, "actor_entropy": 0.3252430409193039, "alpha_loss": -0.013394206017255782, "alpha_value": 0.18167200708904802, "duration": 7.271358966827393, "step": 47000}
{"episode_reward": 172.68393341123476, "episode": 377.0, "batch_reward": 1.7017575979232789, "critic_loss": 27.027270126342774, "actor_loss": -203.90420532226562, "actor_target_entropy": -1.0, "actor_entropy": 0.3440154820680618, "alpha_loss": -0.00036216191947460177, "alpha_value": 0.18300439082424202, "duration": 7.115141153335571, "step": 47500}
{"episode_reward": 261.76202093142547, "episode": 381.0, "batch_reward": 1.754369354248047, "critic_loss": 16.438347244262694, "actor_loss": -205.56073608398438, "actor_target_entropy": -1.0, "actor_entropy": 0.27157245576381683, "alpha_loss": -0.006222866289317608, "alpha_value": 0.1844617952858625, "duration": 7.254937410354614, "step": 48000}
{"episode_reward": 309.10016949065874, "episode": 385.0, "batch_reward": 1.85569224357605, "critic_loss": 23.154631423950196, "actor_loss": -206.6703338623047, "actor_target_entropy": -1.0, "actor_entropy": 0.32153406739234924, "alpha_loss": 0.008635042235255241, "alpha_value": 0.18545371942768132, "duration": 7.1262876987457275, "step": 48500}
{"episode_reward": 294.27348878415046, "episode": 389.0, "batch_reward": 1.8566042900085449, "critic_loss": 30.602496910095216, "actor_loss": -207.11851196289064, "actor_target_entropy": -1.0, "actor_entropy": 0.3265600264072418, "alpha_loss": 0.004510650038719177, "alpha_value": 0.18632045217536633, "duration": 7.19206166267395, "step": 49000}
{"episode_reward": 233.25015645912464, "episode": 393.0, "batch_reward": 1.6811768531799316, "critic_loss": 28.02151985168457, "actor_loss": -207.7260955810547, "actor_target_entropy": -1.0, "actor_entropy": 0.3066084057092667, "alpha_loss": -0.010672984831035136, "alpha_value": 0.1875145775559059, "duration": 7.119941473007202, "step": 49500}
{"episode_reward": 248.47573527169686, "episode": 397.0, "batch_reward": 1.6805614233016968, "critic_loss": 31.463365173339845, "actor_loss": -208.94587097167968, "actor_target_entropy": -1.0, "actor_entropy": 0.32588195204734804, "alpha_loss": -0.0005264727398753167, "alpha_value": 0.1892258301672603, "step": 50000}
{"duration": 23.412464380264282, "step": 50000}
{"episode_reward": 193.3808178093427, "episode": 401.0, "batch_reward": 1.7077705144882203, "critic_loss": 22.60889587402344, "actor_loss": -208.49749145507812, "actor_target_entropy": -1.0, "actor_entropy": 0.32664151191711427, "alpha_loss": -0.0037551015615463258, "alpha_value": 0.18972816866517694, "duration": 7.299732446670532, "step": 50500}
{"episode_reward": 218.328536871277, "episode": 405.0, "batch_reward": 1.8735433101654053, "critic_loss": 22.541239547729493, "actor_loss": -210.46892395019532, "actor_target_entropy": -1.0, "actor_entropy": 0.2590125620365143, "alpha_loss": -0.004247076855972409, "alpha_value": 0.19034406245708227, "duration": 7.093852758407593, "step": 51000}
{"episode_reward": 194.710516952329, "episode": 409.0, "batch_reward": 1.7417897224426269, "critic_loss": 19.103434371948243, "actor_loss": -210.20301208496093, "actor_target_entropy": -1.0, "actor_entropy": 0.4029955923557281, "alpha_loss": -0.027631818410009147, "alpha_value": 0.19178107309934794, "duration": 7.104763507843018, "step": 51500}
{"episode_reward": 205.8725764465977, "episode": 413.0, "batch_reward": 1.8155893087387085, "critic_loss": 28.29348831176758, "actor_loss": -211.45154724121093, "actor_target_entropy": -1.0, "actor_entropy": 0.3381643831729889, "alpha_loss": -0.016882623778656125, "alpha_value": 0.19338428537311927, "duration": 7.1381516456604, "step": 52000}
{"episode_reward": 244.97219685333536, "episode": 417.0, "batch_reward": 1.832786464691162, "critic_loss": 25.979519653320313, "actor_loss": -212.01499938964844, "actor_target_entropy": -1.0, "actor_entropy": 0.3341576814651489, "alpha_loss": 0.025938689708709717, "alpha_value": 0.19367257963658863, "duration": 7.146962404251099, "step": 52500}
{"episode_reward": 215.9322037876704, "episode": 421.0, "batch_reward": 1.7765214443206787, "critic_loss": 23.746171951293945, "actor_loss": -212.43775024414063, "actor_target_entropy": -1.0, "actor_entropy": 0.25622511506080625, "alpha_loss": 0.0017765917815268039, "alpha_value": 0.19381532987916245, "duration": 7.093015909194946, "step": 53000}
{"episode_reward": 237.4148258242245, "episode": 425.0, "batch_reward": 1.7222578287124635, "critic_loss": 26.234043502807616, "actor_loss": -212.6146484375, "actor_target_entropy": -1.0, "actor_entropy": 0.3175518661737442, "alpha_loss": -0.008819889277219772, "alpha_value": 0.19393172481074145, "duration": 7.146416425704956, "step": 53500}
{"episode_reward": 237.40546680728394, "episode": 429.0, "batch_reward": 1.7732161045074464, "critic_loss": 26.092217254638673, "actor_loss": -213.7187286376953, "actor_target_entropy": -1.0, "actor_entropy": 0.3507197558879852, "alpha_loss": -0.008636066317558288, "alpha_value": 0.1951259557353979, "duration": 7.529129981994629, "step": 54000}
{"episode_reward": 259.26438309481574, "episode": 433.0, "batch_reward": 1.7698166608810424, "critic_loss": 20.39047317504883, "actor_loss": -214.0318817138672, "actor_target_entropy": -1.0, "actor_entropy": 0.34325283467769624, "alpha_loss": 0.0031476239673793316, "alpha_value": 0.1960026487255286, "duration": 7.176990985870361, "step": 54500}
{"episode_reward": 226.4208436242267, "episode": 437.0, "batch_reward": 1.743831205368042, "critic_loss": 27.84768466949463, "actor_loss": -214.9962188720703, "actor_target_entropy": -1.0, "actor_entropy": 0.2823682725429535, "alpha_loss": -0.015741178765892982, "alpha_value": 0.1956733292582912, "duration": 7.05322527885437, "step": 55000}
{"episode_reward": 356.1069422853369, "episode": 441.0, "batch_reward": 1.8579234600067138, "critic_loss": 19.818233489990234, "actor_loss": -216.2193176269531, "actor_target_entropy": -1.0, "actor_entropy": 0.34313146471977235, "alpha_loss": 0.02590639963746071, "alpha_value": 0.1953082525247852, "duration": 7.086689710617065, "step": 55500}
{"episode_reward": 264.841519620091, "episode": 445.0, "batch_reward": 1.7968689680099488, "critic_loss": 22.009928894042968, "actor_loss": -216.70274963378907, "actor_target_entropy": -1.0, "actor_entropy": 0.38162522912025454, "alpha_loss": 0.003958846814930439, "alpha_value": 0.19472461109717026, "duration": 7.061014890670776, "step": 56000}
{"episode_reward": 274.62462370325204, "episode": 449.0, "batch_reward": 1.8400185585021973, "critic_loss": 25.679661560058594, "actor_loss": -216.98745422363282, "actor_target_entropy": -1.0, "actor_entropy": 0.31556229293346405, "alpha_loss": -0.007149045262485743, "alpha_value": 0.19573412762335302, "duration": 7.0417821407318115, "step": 56500}
{"episode_reward": 219.47616812368085, "episode": 453.0, "batch_reward": 1.8023171901702881, "critic_loss": 23.529586029052734, "actor_loss": -217.65408325195312, "actor_target_entropy": -1.0, "actor_entropy": 0.2809748321771622, "alpha_loss": 0.0036683859303593635, "alpha_value": 0.1960495564187063, "duration": 7.088944673538208, "step": 57000}
{"episode_reward": 181.1475840382037, "episode": 457.0, "batch_reward": 1.7936917304992677, "critic_loss": 25.219772720336913, "actor_loss": -219.0316955566406, "actor_target_entropy": -1.0, "actor_entropy": 0.3022192418575287, "alpha_loss": -0.010057087242603301, "alpha_value": 0.19612564068831126, "duration": 7.130551815032959, "step": 57500}
{"episode_reward": 286.6434851318095, "episode": 461.0, "batch_reward": 1.838784146308899, "critic_loss": 23.398333168029787, "actor_loss": -219.90560913085938, "actor_target_entropy": -1.0, "actor_entropy": 0.2910930961370468, "alpha_loss": -0.0026494957506656646, "alpha_value": 0.19645767745698797, "duration": 7.0775368213653564, "step": 58000}
{"episode_reward": 200.3968539522988, "episode": 465.0, "batch_reward": 1.7235897064208985, "critic_loss": 21.782773590087892, "actor_loss": -219.24075317382812, "actor_target_entropy": -1.0, "actor_entropy": 0.31581381559371946, "alpha_loss": -0.00657541798427701, "alpha_value": 0.1959303262669582, "duration": 7.027729034423828, "step": 58500}
{"episode_reward": 183.26933795889963, "episode": 469.0, "batch_reward": 1.8703531503677369, "critic_loss": 22.821326446533202, "actor_loss": -219.91567687988282, "actor_target_entropy": -1.0, "actor_entropy": 0.3496849358081818, "alpha_loss": 0.004691795632243157, "alpha_value": 0.1950720229373512, "duration": 6.965609312057495, "step": 59000}
{"episode_reward": 235.22417179192496, "episode": 473.0, "batch_reward": 1.7095274686813355, "critic_loss": 29.481915283203126, "actor_loss": -220.3209197998047, "actor_target_entropy": -1.0, "actor_entropy": 0.31489861011505127, "alpha_loss": 0.0027126170694828033, "alpha_value": 0.19477242998889358, "duration": 7.048247575759888, "step": 59500}
{"episode_reward": 231.73289880632686, "episode": 477.0, "batch_reward": 1.8136590480804444, "critic_loss": 23.113439559936523, "actor_loss": -221.11795654296876, "actor_target_entropy": -1.0, "actor_entropy": 0.3234912693500519, "alpha_loss": 0.008250953629612923, "alpha_value": 0.1952937866794481, "step": 60000}
{"duration": 23.587950706481934, "step": 60000}
{"episode_reward": 299.3654868076801, "episode": 481.0, "batch_reward": 1.7180243968963622, "critic_loss": 25.034639739990233, "actor_loss": -221.35921630859374, "actor_target_entropy": -1.0, "actor_entropy": 0.3846299767494202, "alpha_loss": 0.007597872149199247, "alpha_value": 0.19532866653621886, "duration": 6.99896502494812, "step": 60500}
{"episode_reward": 198.04038014957175, "episode": 485.0, "batch_reward": 1.8222055673599242, "critic_loss": 26.646258544921874, "actor_loss": -221.10964660644532, "actor_target_entropy": -1.0, "actor_entropy": 0.3616192936897278, "alpha_loss": 0.01139343474060297, "alpha_value": 0.19417588393651647, "duration": 7.012463092803955, "step": 61000}
{"episode_reward": 242.02579052485612, "episode": 489.0, "batch_reward": 1.7139060497283936, "critic_loss": 30.578367614746092, "actor_loss": -222.00631408691407, "actor_target_entropy": -1.0, "actor_entropy": 0.3482386708259583, "alpha_loss": -0.010974939540028572, "alpha_value": 0.19381693789164334, "duration": 7.051397800445557, "step": 61500}
{"episode_reward": 212.12395916414576, "episode": 493.0, "batch_reward": 1.7943524599075318, "critic_loss": 22.448322677612303, "actor_loss": -222.64852905273438, "actor_target_entropy": -1.0, "actor_entropy": 0.35851510763168337, "alpha_loss": 0.004467131197452545, "alpha_value": 0.19500201703973616, "duration": 7.392653942108154, "step": 62000}
{"episode_reward": 302.3432884532107, "episode": 497.0, "batch_reward": 1.9072874307632446, "critic_loss": 23.01932258605957, "actor_loss": -222.60952758789062, "actor_target_entropy": -1.0, "actor_entropy": 0.33350897431373594, "alpha_loss": -0.01895036082714796, "alpha_value": 0.19452938182766016, "duration": 7.018675804138184, "step": 62500}
{"episode_reward": 258.3660168172745, "episode": 501.0, "batch_reward": 1.7639042377471923, "critic_loss": 23.698762893676758, "actor_loss": -222.95274353027344, "actor_target_entropy": -1.0, "actor_entropy": 0.39462247490882874, "alpha_loss": 0.008524513617157937, "alpha_value": 0.19441635080984931, "duration": 7.053292274475098, "step": 63000}
{"episode_reward": 185.4584885257793, "episode": 505.0, "batch_reward": 1.7080470085144044, "critic_loss": 19.360174942016602, "actor_loss": -222.72405395507812, "actor_target_entropy": -1.0, "actor_entropy": 0.38107518553733827, "alpha_loss": 0.013696218468248844, "alpha_value": 0.19393112472441004, "duration": 7.4997804164886475, "step": 63500}
{"episode_reward": 159.496844297293, "episode": 509.0, "batch_reward": 1.8288338661193848, "critic_loss": 29.506192016601563, "actor_loss": -223.9942169189453, "actor_target_entropy": -1.0, "actor_entropy": 0.28160887360572817, "alpha_loss": -0.01435183361172676, "alpha_value": 0.1928238526055909, "duration": 7.492242336273193, "step": 64000}
{"episode_reward": 222.22475684069803, "episode": 513.0, "batch_reward": 1.8806260108947754, "critic_loss": 22.028458023071288, "actor_loss": -223.98170166015626, "actor_target_entropy": -1.0, "actor_entropy": 0.2964794099330902, "alpha_loss": 0.008127470500767231, "alpha_value": 0.19223990205022887, "duration": 7.014486312866211, "step": 64500}
{"episode_reward": 204.60217648076184, "episode": 517.0, "batch_reward": 1.7777822256088256, "critic_loss": 19.97593879699707, "actor_loss": -223.87652282714845, "actor_target_entropy": -1.0, "actor_entropy": 0.3636478841304779, "alpha_loss": -0.00018045473843812941, "alpha_value": 0.1919353285910737, "duration": 6.970316171646118, "step": 65000}
{"episode_reward": 280.09804825659927, "episode": 521.0, "batch_reward": 1.8342227697372437, "critic_loss": 30.720144271850586, "actor_loss": -224.88057556152344, "actor_target_entropy": -1.0, "actor_entropy": 0.4125185012817383, "alpha_loss": 0.029327089432626963, "alpha_value": 0.19263832080332283, "duration": 7.027532339096069, "step": 65500}
{"episode_reward": 193.94486625429366, "episode": 525.0, "batch_reward": 1.7833916187286376, "critic_loss": 21.95967502593994, "actor_loss": -225.05404968261718, "actor_target_entropy": -1.0, "actor_entropy": 0.3298842400312424, "alpha_loss": -0.015294007211923599, "alpha_value": 0.19225670590526986, "duration": 6.952988862991333, "step": 66000}
{"episode_reward": 269.1016240729835, "episode": 529.0, "batch_reward": 1.7982838153839111, "critic_loss": 19.76341323852539, "actor_loss": -225.42295837402344, "actor_target_entropy": -1.0, "actor_entropy": 0.3150024592876434, "alpha_loss": -0.012270941492170095, "alpha_value": 0.19218588526063202, "duration": 7.008029460906982, "step": 66500}
{"episode_reward": 214.4647854716096, "episode": 533.0, "batch_reward": 1.7961018085479736, "critic_loss": 17.643132209777832, "actor_loss": -227.3430419921875, "actor_target_entropy": -1.0, "actor_entropy": 0.35193358063697816, "alpha_loss": -0.014941854402422905, "alpha_value": 0.19233015092414102, "duration": 7.027622699737549, "step": 67000}
{"episode_reward": 267.3825349112027, "episode": 537.0, "batch_reward": 1.7570279121398926, "critic_loss": 18.910584259033204, "actor_loss": -226.34581604003907, "actor_target_entropy": -1.0, "actor_entropy": 0.3506300002336502, "alpha_loss": 0.005440079420804977, "alpha_value": 0.1924072888713707, "duration": 7.1521155834198, "step": 67500}
{"episode_reward": 231.4309647921968, "episode": 541.0, "batch_reward": 1.6738692760467528, "critic_loss": 21.118660736083985, "actor_loss": -226.11033630371094, "actor_target_entropy": -1.0, "actor_entropy": 0.4093142032623291, "alpha_loss": 0.021377823129296303, "alpha_value": 0.19255496493030919, "duration": 7.492609739303589, "step": 68000}
{"episode_reward": 200.88606981210808, "episode": 545.0, "batch_reward": 1.7730335474014283, "critic_loss": 21.15625114440918, "actor_loss": -227.82616271972657, "actor_target_entropy": -1.0, "actor_entropy": 0.35995137095451357, "alpha_loss": -0.009407402947545052, "alpha_value": 0.1922639023914537, "duration": 7.049252271652222, "step": 68500}
{"episode_reward": 315.8248777349433, "episode": 549.0, "batch_reward": 2.1021117210388183, "critic_loss": 22.087879943847657, "actor_loss": -229.44363403320312, "actor_target_entropy": -1.0, "actor_entropy": 0.2534239888191223, "alpha_loss": 0.024928844533860683, "alpha_value": 0.19162593810335243, "duration": 7.1426496505737305, "step": 69000}
{"episode_reward": 262.4472132468006, "episode": 553.0, "batch_reward": 1.87546808719635, "critic_loss": 26.718507957458495, "actor_loss": -228.24860534667968, "actor_target_entropy": -1.0, "actor_entropy": 0.2697114050388336, "alpha_loss": 0.003073020279407501, "alpha_value": 0.19125076241138741, "duration": 7.229912996292114, "step": 69500}
{"episode_reward": 217.56964819920626, "episode": 557.0, "batch_reward": 1.7260610818862916, "critic_loss": 20.01522579193115, "actor_loss": -228.82653198242187, "actor_target_entropy": -1.0, "actor_entropy": 0.33331034779548646, "alpha_loss": -0.008553236164152623, "alpha_value": 0.19067447452908262, "step": 70000}
{"duration": 27.148422718048096, "step": 70000}
{"episode_reward": 223.75382042475016, "episode": 561.0, "batch_reward": 1.7732850313186646, "critic_loss": 19.598801040649413, "actor_loss": -228.9402618408203, "actor_target_entropy": -1.0, "actor_entropy": 0.2930956304073334, "alpha_loss": -0.00680275522172451, "alpha_value": 0.19055635322793138, "duration": 7.218918800354004, "step": 70500}
{"episode_reward": 296.7263382691427, "episode": 565.0, "batch_reward": 1.834888219833374, "critic_loss": 24.47548885345459, "actor_loss": -229.12657775878907, "actor_target_entropy": -1.0, "actor_entropy": 0.3099521994590759, "alpha_loss": -0.01795424222946167, "alpha_value": 0.1898247432071812, "duration": 7.234867334365845, "step": 71000}
{"episode_reward": 373.55255157560185, "episode": 569.0, "batch_reward": 1.7700406074523927, "critic_loss": 30.480961990356445, "actor_loss": -229.09599914550782, "actor_target_entropy": -1.0, "actor_entropy": 0.3056985318660736, "alpha_loss": -0.020507460087537767, "alpha_value": 0.19041957342196122, "duration": 7.226854562759399, "step": 71500}
{"episode_reward": 229.75432588272793, "episode": 573.0, "batch_reward": 1.7870636701583862, "critic_loss": 29.43539161682129, "actor_loss": -229.69004516601564, "actor_target_entropy": -1.0, "actor_entropy": 0.3372164726257324, "alpha_loss": -0.021340178325772285, "alpha_value": 0.19055925823309142, "duration": 7.4442665576934814, "step": 72000}
{"episode_reward": 235.58964798064548, "episode": 577.0, "batch_reward": 1.8224992275238037, "critic_loss": 20.43437080383301, "actor_loss": -229.96569213867187, "actor_target_entropy": -1.0, "actor_entropy": 0.3538412511348724, "alpha_loss": 0.01663886457681656, "alpha_value": 0.19032477416123672, "duration": 7.3268232345581055, "step": 72500}
{"episode_reward": 234.5213892310204, "episode": 581.0, "batch_reward": 1.8283339738845825, "critic_loss": 23.29799461364746, "actor_loss": -229.13357543945312, "actor_target_entropy": -1.0, "actor_entropy": 0.4014731884002686, "alpha_loss": 0.010009719338268042, "alpha_value": 0.1903670137258026, "duration": 7.229846000671387, "step": 73000}
{"episode_reward": 230.50736248148982, "episode": 585.0, "batch_reward": 1.7013738870620727, "critic_loss": 23.107740783691405, "actor_loss": -230.05042114257813, "actor_target_entropy": -1.0, "actor_entropy": 0.29734032452106474, "alpha_loss": 0.005141223780810833, "alpha_value": 0.18984642409711452, "duration": 7.490018367767334, "step": 73500}
{"episode_reward": 248.82463940345193, "episode": 589.0, "batch_reward": 1.79499351978302, "critic_loss": 22.941698837280274, "actor_loss": -230.13019714355468, "actor_target_entropy": -1.0, "actor_entropy": 0.3450048744678497, "alpha_loss": 0.007851416617631913, "alpha_value": 0.18939618667168084, "duration": 7.439314126968384, "step": 74000}
{"episode_reward": 350.852976551141, "episode": 593.0, "batch_reward": 1.8172158479690552, "critic_loss": 27.42185287475586, "actor_loss": -230.6966522216797, "actor_target_entropy": -1.0, "actor_entropy": 0.3493496596813202, "alpha_loss": -0.012621369026601315, "alpha_value": 0.18848449830561717, "duration": 8.032205581665039, "step": 74500}
{"episode_reward": 309.7444658052887, "episode": 597.0, "batch_reward": 1.8860948085784912, "critic_loss": 21.049161529541017, "actor_loss": -230.8248779296875, "actor_target_entropy": -1.0, "actor_entropy": 0.3495695412158966, "alpha_loss": -0.0027346710674464704, "alpha_value": 0.1873356814380897, "duration": 7.751966714859009, "step": 75000}
{"episode_reward": 263.8439767082661, "episode": 601.0, "batch_reward": 1.8713043689727784, "critic_loss": 23.455493545532228, "actor_loss": -230.74404296875, "actor_target_entropy": -1.0, "actor_entropy": 0.3685097932815552, "alpha_loss": 0.0025765810161828993, "alpha_value": 0.1871429357010692, "duration": 7.567727088928223, "step": 75500}
{"episode_reward": 202.61649966830257, "episode": 605.0, "batch_reward": 1.8353609561920166, "critic_loss": 19.005679321289062, "actor_loss": -231.03859252929686, "actor_target_entropy": -1.0, "actor_entropy": 0.3540498912334442, "alpha_loss": 0.0032216666266322138, "alpha_value": 0.1869909276081202, "duration": 7.381765842437744, "step": 76000}
{"episode_reward": 173.02052020015842, "episode": 609.0, "batch_reward": 1.8334007740020752, "critic_loss": 27.8450870513916, "actor_loss": -232.18023986816405, "actor_target_entropy": -1.0, "actor_entropy": 0.3308094382286072, "alpha_loss": -0.010507734678685664, "alpha_value": 0.1867338465840435, "duration": 7.556234359741211, "step": 76500}
{"episode_reward": 125.49682095697607, "episode": 613.0, "batch_reward": 1.7320489645004273, "critic_loss": 24.298321342468263, "actor_loss": -230.9974334716797, "actor_target_entropy": -1.0, "actor_entropy": 0.3334908902645111, "alpha_loss": -0.017633034195750952, "alpha_value": 0.18577050871252185, "duration": 7.564269781112671, "step": 77000}
{"episode_reward": 283.3629213265045, "episode": 617.0, "batch_reward": 1.8834642887115478, "critic_loss": 25.98964500427246, "actor_loss": -232.29184265136718, "actor_target_entropy": -1.0, "actor_entropy": 0.33419427275657654, "alpha_loss": 0.00020400863140821457, "alpha_value": 0.18583822187947624, "duration": 7.7436792850494385, "step": 77500}
{"episode_reward": 242.72721808453832, "episode": 621.0, "batch_reward": 1.8393433094024658, "critic_loss": 27.075439453125, "actor_loss": -232.46752319335937, "actor_target_entropy": -1.0, "actor_entropy": 0.35952728390693667, "alpha_loss": -0.0161483459174633, "alpha_value": 0.18563419416271904, "duration": 7.223271369934082, "step": 78000}
{"episode_reward": 240.7153208524775, "episode": 625.0, "batch_reward": 1.7819061994552612, "critic_loss": 21.772935485839845, "actor_loss": -232.41893920898437, "actor_target_entropy": -1.0, "actor_entropy": 0.3193290263414383, "alpha_loss": 0.006795065104961395, "alpha_value": 0.18600553044227214, "duration": 7.228995323181152, "step": 78500}
{"episode_reward": 202.2644035703572, "episode": 629.0, "batch_reward": 1.8741969823837281, "critic_loss": 21.42653884887695, "actor_loss": -234.0012237548828, "actor_target_entropy": -1.0, "actor_entropy": 0.3140244722366333, "alpha_loss": 0.008067021565511822, "alpha_value": 0.18568272757313048, "duration": 8.017774105072021, "step": 79000}
{"episode_reward": 240.3332946519975, "episode": 633.0, "batch_reward": 1.693476939201355, "critic_loss": 17.640598106384278, "actor_loss": -231.72523803710936, "actor_target_entropy": -1.0, "actor_entropy": 0.36481612026691435, "alpha_loss": -0.013144522719085217, "alpha_value": 0.18624834705424023, "duration": 8.074944257736206, "step": 79500}
{"episode_reward": 243.01940113763743, "episode": 637.0, "batch_reward": 1.8774300813674927, "critic_loss": 23.84401206970215, "actor_loss": -233.77808837890626, "actor_target_entropy": -1.0, "actor_entropy": 0.33415278792381287, "alpha_loss": 0.00411745710298419, "alpha_value": 0.18668779683172548, "step": 80000}
{"duration": 23.873626470565796, "step": 80000}
{"episode_reward": 181.77123384341425, "episode": 641.0, "batch_reward": 1.7589614391326904, "critic_loss": 22.574776458740235, "actor_loss": -233.83091735839844, "actor_target_entropy": -1.0, "actor_entropy": 0.3399979770183563, "alpha_loss": 0.00508659677579999, "alpha_value": 0.18689016731313932, "duration": 8.048930883407593, "step": 80500}
{"episode_reward": 172.62022616518703, "episode": 645.0, "batch_reward": 1.6890341520309449, "critic_loss": 20.859580993652344, "actor_loss": -234.50633239746094, "actor_target_entropy": -1.0, "actor_entropy": 0.27942111194133756, "alpha_loss": -0.027437430806457996, "alpha_value": 0.1874183478651359, "duration": 7.294503688812256, "step": 81000}
{"episode_reward": 153.2817380960648, "episode": 649.0, "batch_reward": 1.8227314472198486, "critic_loss": 21.271330261230467, "actor_loss": -234.80917663574218, "actor_target_entropy": -1.0, "actor_entropy": 0.3736876010894775, "alpha_loss": 7.616914808750153e-05, "alpha_value": 0.18773540410612669, "duration": 7.36796760559082, "step": 81500}
{"episode_reward": 250.43819971022316, "episode": 653.0, "batch_reward": 1.8029851913452148, "critic_loss": 28.52798500061035, "actor_loss": -235.7089080810547, "actor_target_entropy": -1.0, "actor_entropy": 0.30636849999427795, "alpha_loss": -0.007062641344964505, "alpha_value": 0.18792696997289177, "duration": 7.372263431549072, "step": 82000}
{"episode_reward": 221.78255329845607, "episode": 657.0, "batch_reward": 1.9591605901718139, "critic_loss": 24.55396842956543, "actor_loss": -235.45453491210938, "actor_target_entropy": -1.0, "actor_entropy": 0.23238956928253174, "alpha_loss": 0.0009469442069530487, "alpha_value": 0.18855470651977468, "duration": 10.148065567016602, "step": 82500}
{"episode_reward": 245.0576685316143, "episode": 661.0, "batch_reward": 1.981720781326294, "critic_loss": 21.789897155761718, "actor_loss": -236.1346466064453, "actor_target_entropy": -1.0, "actor_entropy": 0.3437323570251465, "alpha_loss": 0.010620829369872808, "alpha_value": 0.1895594529979034, "duration": 7.713037014007568, "step": 83000}
{"episode_reward": 39.35085846665562, "episode": 665.0, "batch_reward": 1.718807005882263, "critic_loss": 18.68873882293701, "actor_loss": -235.5500946044922, "actor_target_entropy": -1.0, "actor_entropy": 0.4139735758304596, "alpha_loss": 0.004714370192959905, "alpha_value": 0.19007797061221327, "duration": 7.373492002487183, "step": 83500}
{"episode_reward": 185.84226244874006, "episode": 669.0, "batch_reward": 1.779197907447815, "critic_loss": 30.7211669921875, "actor_loss": -236.43488159179688, "actor_target_entropy": -1.0, "actor_entropy": 0.34910195469856264, "alpha_loss": -0.014102640934288502, "alpha_value": 0.1903643616977398, "duration": 7.2788307666778564, "step": 84000}
{"episode_reward": 137.55070870097265, "episode": 673.0, "batch_reward": 1.8624576807022095, "critic_loss": 20.971730041503907, "actor_loss": -237.5481170654297, "actor_target_entropy": -1.0, "actor_entropy": 0.26787503361701964, "alpha_loss": 0.01197194685228169, "alpha_value": 0.19034179538449106, "duration": 7.207357168197632, "step": 84500}
{"episode_reward": 67.12890906931784, "episode": 677.0, "batch_reward": 1.9005741119384765, "critic_loss": 20.37822380065918, "actor_loss": -237.4029998779297, "actor_target_entropy": -1.0, "actor_entropy": 0.3443759262561798, "alpha_loss": -0.009145709313452243, "alpha_value": 0.19083004948293372, "duration": 7.730226516723633, "step": 85000}
{"episode_reward": 195.7042732963397, "episode": 681.0, "batch_reward": 1.8870532035827636, "critic_loss": 20.03981704711914, "actor_loss": -237.92706298828125, "actor_target_entropy": -1.0, "actor_entropy": 0.3144154906272888, "alpha_loss": -0.009297776035964489, "alpha_value": 0.191152322417416, "duration": 7.272600412368774, "step": 85500}
{"episode_reward": 94.83357295290848, "episode": 685.0, "batch_reward": 1.5671660423278808, "critic_loss": 19.128137588500977, "actor_loss": -236.80792846679688, "actor_target_entropy": -1.0, "actor_entropy": 0.3745861232280731, "alpha_loss": -0.010882011987268925, "alpha_value": 0.19329449663660564, "duration": 7.240336656570435, "step": 86000}
{"episode_reward": 56.844193727215654, "episode": 689.0, "batch_reward": 1.7232110261917115, "critic_loss": 21.879074478149413, "actor_loss": -237.69590454101564, "actor_target_entropy": -1.0, "actor_entropy": 0.3696472942829132, "alpha_loss": 0.005190193280577659, "alpha_value": 0.19399821486610908, "duration": 7.675778388977051, "step": 86500}
{"episode_reward": 59.65898342427682, "episode": 693.0, "batch_reward": 1.775548529624939, "critic_loss": 29.706239700317383, "actor_loss": -238.851806640625, "actor_target_entropy": -1.0, "actor_entropy": 0.3610337138175964, "alpha_loss": -0.025316453352570534, "alpha_value": 0.194503575565126, "duration": 13.877042293548584, "step": 87000}
{"episode_reward": 71.57011447306698, "episode": 697.0, "batch_reward": 1.8093669891357422, "critic_loss": 23.122436141967775, "actor_loss": -238.92359313964843, "actor_target_entropy": -1.0, "actor_entropy": 0.3135860234498978, "alpha_loss": -0.0017846709117293358, "alpha_value": 0.1959399226882505, "duration": 9.137190580368042, "step": 87500}
{"episode_reward": 53.41739526202358, "episode": 701.0, "batch_reward": 1.7556692123413087, "critic_loss": 17.751194763183594, "actor_loss": -238.80309448242187, "actor_target_entropy": -1.0, "actor_entropy": 0.3122472405433655, "alpha_loss": 0.0009157905355095863, "alpha_value": 0.1967389530406392, "duration": 9.82608413696289, "step": 88000}
{"episode_reward": 51.81819239086593, "episode": 705.0, "batch_reward": 1.7829266309738159, "critic_loss": 21.65605697631836, "actor_loss": -240.44271545410157, "actor_target_entropy": -1.0, "actor_entropy": 0.24164407551288605, "alpha_loss": 0.012693581078201533, "alpha_value": 0.19752614085287928, "duration": 8.757949590682983, "step": 88500}
{"episode_reward": 63.76562809364297, "episode": 709.0, "batch_reward": 1.8314954042434692, "critic_loss": 20.401597213745116, "actor_loss": -240.56567993164063, "actor_target_entropy": -1.0, "actor_entropy": 0.3295465350151062, "alpha_loss": -0.020397922955453396, "alpha_value": 0.19847757573039287, "duration": 8.735747337341309, "step": 89000}
{"episode_reward": 33.221088936236335, "episode": 713.0, "batch_reward": 1.721378493309021, "critic_loss": 18.66683292388916, "actor_loss": -240.3854949951172, "actor_target_entropy": -1.0, "actor_entropy": 0.3408945858478546, "alpha_loss": -0.00875090267509222, "alpha_value": 0.19913821231932044, "duration": 8.070226192474365, "step": 89500}
{"episode_reward": 68.45409763164584, "episode": 717.0, "batch_reward": 1.708919382095337, "critic_loss": 24.342736434936523, "actor_loss": -239.81170349121095, "actor_target_entropy": -1.0, "actor_entropy": 0.29921159744262693, "alpha_loss": -0.001181978452950716, "alpha_value": 0.20103414111007173, "step": 90000}
{"duration": 25.428149700164795, "step": 90000}
{"episode_reward": 49.672965464313314, "episode": 721.0, "batch_reward": 1.6051987648010253, "critic_loss": 19.81740074157715, "actor_loss": -241.24095764160157, "actor_target_entropy": -1.0, "actor_entropy": 0.3634728014469147, "alpha_loss": -0.026605332642793654, "alpha_value": 0.20308062647243771, "duration": 11.123411893844604, "step": 90500}
{"episode_reward": 69.55918601145896, "episode": 725.0, "batch_reward": 1.764195442199707, "critic_loss": 15.913854598999023, "actor_loss": -241.4851531982422, "actor_target_entropy": -1.0, "actor_entropy": 0.35549023747444153, "alpha_loss": -0.017279668897390365, "alpha_value": 0.20438071353362294, "duration": 24.51723623275757, "step": 91000}
{"episode_reward": 64.4614029883159, "episode": 729.0, "batch_reward": 1.7292681217193604, "critic_loss": 22.32989387512207, "actor_loss": -242.33755187988282, "actor_target_entropy": -1.0, "actor_entropy": 0.2682942390441895, "alpha_loss": -0.007672400027513504, "alpha_value": 0.20470497344563993, "duration": 12.470030307769775, "step": 91500}
{"episode_reward": 56.53033974351789, "episode": 733.0, "batch_reward": 1.715639090538025, "critic_loss": 19.10317497253418, "actor_loss": -241.713671875, "actor_target_entropy": -1.0, "actor_entropy": 0.34641551673412324, "alpha_loss": 0.0035929948091506956, "alpha_value": 0.20420348690474013, "duration": 9.16672134399414, "step": 92000}
{"episode_reward": 80.94949282350282, "episode": 737.0, "batch_reward": 1.754655408859253, "critic_loss": 21.043380165100096, "actor_loss": -242.18712768554687, "actor_target_entropy": -1.0, "actor_entropy": 0.3555491864681244, "alpha_loss": 0.002848324365913868, "alpha_value": 0.2047636071185445, "duration": 9.416724443435669, "step": 92500}
{"episode_reward": 53.978511169386195, "episode": 741.0, "batch_reward": 1.5469583511352538, "critic_loss": 22.201864624023436, "actor_loss": -241.88828125, "actor_target_entropy": -1.0, "actor_entropy": 0.35253686606884005, "alpha_loss": 0.008820059522986413, "alpha_value": 0.20515879827180386, "duration": 16.014822959899902, "step": 93000}
{"episode_reward": 41.99357369136929, "episode": 745.0, "batch_reward": 1.6561527490615844, "critic_loss": 28.312541580200197, "actor_loss": -243.64095153808594, "actor_target_entropy": -1.0, "actor_entropy": 0.35984407663345336, "alpha_loss": 0.0019063888117671012, "alpha_value": 0.2055401758824807, "duration": 11.399255275726318, "step": 93500}
{"episode_reward": 50.74540957615541, "episode": 749.0, "batch_reward": 1.739349126815796, "critic_loss": 22.243206787109376, "actor_loss": -243.5561737060547, "actor_target_entropy": -1.0, "actor_entropy": 0.2750910758972168, "alpha_loss": 0.017692359536886214, "alpha_value": 0.20601443088363025, "duration": 24.868868112564087, "step": 94000}
{"episode_reward": 72.13642563421116, "episode": 753.0, "batch_reward": 1.6063600540161134, "critic_loss": 20.108993530273438, "actor_loss": -243.70147094726562, "actor_target_entropy": -1.0, "actor_entropy": 0.3966840088367462, "alpha_loss": -0.015947894565761088, "alpha_value": 0.20706120897666022, "duration": 14.648819923400879, "step": 94500}
{"episode_reward": 46.41979116665637, "episode": 757.0, "batch_reward": 1.7551351308822631, "critic_loss": 23.495263290405273, "actor_loss": -244.99683837890626, "actor_target_entropy": -1.0, "actor_entropy": 0.40698630213737486, "alpha_loss": -0.001881950069218874, "alpha_value": 0.20828357250733243, "duration": 27.835511445999146, "step": 95000}
{"episode_reward": 73.34450522237186, "episode": 761.0, "batch_reward": 1.627638578414917, "critic_loss": 15.508436965942384, "actor_loss": -244.85447998046874, "actor_target_entropy": -1.0, "actor_entropy": 0.3114145427942276, "alpha_loss": 0.009876137971878052, "alpha_value": 0.2087544200730702, "duration": 25.09159278869629, "step": 95500}
{"episode_reward": 65.20220981573313, "episode": 765.0, "batch_reward": 1.5135900974273682, "critic_loss": 24.250572967529298, "actor_loss": -244.6437774658203, "actor_target_entropy": -1.0, "actor_entropy": 0.41958869695663453, "alpha_loss": -0.00496014766395092, "alpha_value": 0.2091713254050655, "duration": 28.2729434967041, "step": 96000}
{"episode_reward": 67.48165902590681, "episode": 769.0, "batch_reward": 1.5994299173355102, "critic_loss": 19.220703887939454, "actor_loss": -245.93651123046874, "actor_target_entropy": -1.0, "actor_entropy": 0.2877829909324646, "alpha_loss": -0.006737421452999115, "alpha_value": 0.21063041432683613, "duration": 28.284107208251953, "step": 96500}
{"episode_reward": 56.6467173999247, "episode": 773.0, "batch_reward": 1.6345404863357544, "critic_loss": 19.98399963378906, "actor_loss": -246.47576599121095, "actor_target_entropy": -1.0, "actor_entropy": 0.38255987167358396, "alpha_loss": 0.00992535138502717, "alpha_value": 0.2109285818645859, "duration": 27.841631174087524, "step": 97000}
{"episode_reward": 41.48173996092204, "episode": 777.0, "batch_reward": 1.5963121414184571, "critic_loss": 25.213202667236327, "actor_loss": -245.85275268554688, "actor_target_entropy": -1.0, "actor_entropy": 0.4031743586063385, "alpha_loss": 0.0004656627774238586, "alpha_value": 0.21153413966977647, "duration": 31.32554841041565, "step": 97500}
{"episode_reward": 213.5082774771974, "episode": 781.0, "batch_reward": 1.562348222732544, "critic_loss": 18.989959716796875, "actor_loss": -247.0480163574219, "actor_target_entropy": -1.0, "actor_entropy": 0.3584166944026947, "alpha_loss": 0.011482723895460368, "alpha_value": 0.21105672030452244, "duration": 27.44339656829834, "step": 98000}
{"episode_reward": 52.65880271773619, "episode": 785.0, "batch_reward": 1.5391497373580934, "critic_loss": 18.222571563720702, "actor_loss": -247.12608947753907, "actor_target_entropy": -1.0, "actor_entropy": 0.32994167804718016, "alpha_loss": 0.00733489990234375, "alpha_value": 0.21197211559694323, "duration": 31.455500602722168, "step": 98500}
{"episode_reward": 36.7976137386664, "episode": 789.0, "batch_reward": 1.6896737575531007, "critic_loss": 17.919133949279786, "actor_loss": -248.01268920898437, "actor_target_entropy": -1.0, "actor_entropy": 0.3376039683818817, "alpha_loss": 0.012406369857490062, "alpha_value": 0.211899393275655, "duration": 55.15083956718445, "step": 99000}
{"episode_reward": 26.531594074861843, "episode": 793.0, "batch_reward": 1.552222728729248, "critic_loss": 18.197608184814452, "actor_loss": -248.07908325195314, "actor_target_entropy": -1.0, "actor_entropy": 0.4265744090080261, "alpha_loss": -0.022442098893225192, "alpha_value": 0.21298250658889323, "duration": 26.987900495529175, "step": 99500}
{"episode_reward": 200.62993606248705, "episode": 797.0, "batch_reward": 1.604054617881775, "critic_loss": 23.044352722167968, "actor_loss": -249.1417236328125, "actor_target_entropy": -1.0, "actor_entropy": 0.4260599076747894, "alpha_loss": -0.035522923618555066, "alpha_value": 0.21399410484731257, "step": 100000}
{"duration": 46.6126024723053, "step": 100000}
{"episode_reward": 279.6717774614569, "episode": 801.0, "batch_reward": 1.584315252304077, "critic_loss": 22.440756797790527, "actor_loss": -249.4448272705078, "actor_target_entropy": -1.0, "actor_entropy": 0.4096673011779785, "alpha_loss": -0.030007423460483552, "alpha_value": 0.21627205254793816, "duration": 28.777196645736694, "step": 100500}
{"episode_reward": 27.808092895630057, "episode": 805.0, "batch_reward": 1.6062028884887696, "critic_loss": 21.700318145751954, "actor_loss": -249.72223205566405, "actor_target_entropy": -1.0, "actor_entropy": 0.3750330150127411, "alpha_loss": -0.009141810424625873, "alpha_value": 0.21706921326498702, "duration": 29.290274381637573, "step": 101000}
{"episode_reward": 61.005768217334634, "episode": 809.0, "batch_reward": 1.5916724443435668, "critic_loss": 17.593516540527343, "actor_loss": -251.07146606445312, "actor_target_entropy": -1.0, "actor_entropy": 0.3944146275520325, "alpha_loss": -0.01478001605719328, "alpha_value": 0.21719089524050655, "duration": 15.414557933807373, "step": 101500}
{"episode_reward": 50.48227255213819, "episode": 813.0, "batch_reward": 1.5351572275161742, "critic_loss": 19.458175659179688, "actor_loss": -251.15146179199218, "actor_target_entropy": -1.0, "actor_entropy": 0.392014741897583, "alpha_loss": -0.006190759874880314, "alpha_value": 0.21601455075239065, "duration": 39.56260323524475, "step": 102000}
{"episode_reward": 69.21812228875505, "episode": 817.0, "batch_reward": 1.585754656791687, "critic_loss": 22.82655200958252, "actor_loss": -250.6537353515625, "actor_target_entropy": -1.0, "actor_entropy": 0.3320410311222076, "alpha_loss": 0.004990321770310402, "alpha_value": 0.2149995256577481, "duration": 29.347721815109253, "step": 102500}
{"episode_reward": 61.349172061597045, "episode": 821.0, "batch_reward": 1.7070257663726807, "critic_loss": 20.13626766204834, "actor_loss": -251.95439758300782, "actor_target_entropy": -1.0, "actor_entropy": 0.31871440410614016, "alpha_loss": 0.0029335392639040945, "alpha_value": 0.21388689252192283, "duration": 30.464252948760986, "step": 103000}
{"episode_reward": 56.53694592981808, "episode": 825.0, "batch_reward": 1.6072848320007325, "critic_loss": 20.557378196716307, "actor_loss": -251.48287963867188, "actor_target_entropy": -1.0, "actor_entropy": 0.3635240375995636, "alpha_loss": 0.019941791146993636, "alpha_value": 0.2135276789386887, "duration": 32.19560194015503, "step": 103500}
{"episode_reward": 122.30301199626936, "episode": 829.0, "batch_reward": 1.6324496746063233, "critic_loss": 23.473543167114258, "actor_loss": -252.17215881347656, "actor_target_entropy": -1.0, "actor_entropy": 0.42174761891365053, "alpha_loss": -0.01805212777107954, "alpha_value": 0.21483035955838553, "duration": 18.884340047836304, "step": 104000}
{"episode_reward": 106.2137214584627, "episode": 833.0, "batch_reward": 1.6680613040924073, "critic_loss": 14.779536056518555, "actor_loss": -253.53128662109376, "actor_target_entropy": -1.0, "actor_entropy": 0.3997939586639404, "alpha_loss": -0.007851013913750648, "alpha_value": 0.21714319339190097, "duration": 28.839030027389526, "step": 104500}
{"episode_reward": 67.81918580516634, "episode": 837.0, "batch_reward": 1.5626360893249511, "critic_loss": 17.64175682067871, "actor_loss": -252.82845458984374, "actor_target_entropy": -1.0, "actor_entropy": 0.3687541365623474, "alpha_loss": -0.001277101505547762, "alpha_value": 0.21764209608064694, "duration": 19.51447820663452, "step": 105000}
{"episode_reward": 175.84560533459575, "episode": 841.0, "batch_reward": 1.7354958295822143, "critic_loss": 24.430403900146484, "actor_loss": -253.9767822265625, "actor_target_entropy": -1.0, "actor_entropy": 0.3642419695854187, "alpha_loss": -0.00983569137752056, "alpha_value": 0.21759533959542035, "duration": 17.742589712142944, "step": 105500}
{"episode_reward": 64.27911509707275, "episode": 845.0, "batch_reward": 1.5849533557891846, "critic_loss": 25.89223003387451, "actor_loss": -254.1514099121094, "actor_target_entropy": -1.0, "actor_entropy": 0.37792242765426637, "alpha_loss": -0.01233114507049322, "alpha_value": 0.21742238734961972, "duration": 18.0765860080719, "step": 106000}
{"episode_reward": 52.69116254895652, "episode": 849.0, "batch_reward": 1.6412845134735108, "critic_loss": 22.92550735473633, "actor_loss": -254.4813720703125, "actor_target_entropy": -1.0, "actor_entropy": 0.4022782027721405, "alpha_loss": 0.014772029221057891, "alpha_value": 0.21674144294883352, "duration": 31.309585571289062, "step": 106500}
{"episode_reward": 63.88695663241755, "episode": 853.0, "batch_reward": 1.583121109008789, "critic_loss": 17.50414752960205, "actor_loss": -252.84996032714844, "actor_target_entropy": -1.0, "actor_entropy": 0.37522523999214175, "alpha_loss": 0.006033531948924064, "alpha_value": 0.2162834061605079, "duration": 33.49169611930847, "step": 107000}
{"episode_reward": 73.15076151166593, "episode": 857.0, "batch_reward": 1.545399022102356, "critic_loss": 17.792134857177736, "actor_loss": -253.68627319335937, "actor_target_entropy": -1.0, "actor_entropy": 0.41265723705291746, "alpha_loss": -0.004817457497119903, "alpha_value": 0.21695792026097482, "duration": 31.23831605911255, "step": 107500}
{"episode_reward": 144.491831778252, "episode": 861.0, "batch_reward": 1.5893746852874755, "critic_loss": 18.106486320495605, "actor_loss": -255.73692932128907, "actor_target_entropy": -1.0, "actor_entropy": 0.4233453571796417, "alpha_loss": -0.019566253200173377, "alpha_value": 0.2165433162736087, "duration": 17.787677764892578, "step": 108000}
{"episode_reward": 29.46955969429294, "episode": 865.0, "batch_reward": 1.4871571063995361, "critic_loss": 20.124782180786134, "actor_loss": -255.08856201171875, "actor_target_entropy": -1.0, "actor_entropy": 0.40752131342887876, "alpha_loss": -0.004259057156741619, "alpha_value": 0.21737779736015145, "duration": 16.064673900604248, "step": 108500}
{"episode_reward": 203.866687763647, "episode": 869.0, "batch_reward": 1.6032235145568847, "critic_loss": 20.892557907104493, "actor_loss": -256.52354125976564, "actor_target_entropy": -1.0, "actor_entropy": 0.4273372769355774, "alpha_loss": -0.020559712126851083, "alpha_value": 0.21816236909499515, "duration": 17.707289457321167, "step": 109000}
{"episode_reward": 67.3995761832639, "episode": 873.0, "batch_reward": 1.4490912199020385, "critic_loss": 25.79648208618164, "actor_loss": -255.93753356933593, "actor_target_entropy": -1.0, "actor_entropy": 0.39619826674461367, "alpha_loss": 0.002830510586500168, "alpha_value": 0.2181981519926405, "duration": 19.677555322647095, "step": 109500}
{"episode_reward": 39.58578573754992, "episode": 877.0, "batch_reward": 1.5820837020874023, "critic_loss": 21.47601203918457, "actor_loss": -255.66051330566407, "actor_target_entropy": -1.0, "actor_entropy": 0.38199838399887087, "alpha_loss": -0.03098866529762745, "alpha_value": 0.21925333155513166, "step": 110000}
{"duration": 37.40927171707153, "step": 110000}
{"episode_reward": 76.00059462634, "episode": 881.0, "batch_reward": 1.4854525327682495, "critic_loss": 16.510657501220702, "actor_loss": -256.78623657226564, "actor_target_entropy": -1.0, "actor_entropy": 0.34452409148216245, "alpha_loss": -0.007683510053902864, "alpha_value": 0.21984646370312336, "duration": 15.545137405395508, "step": 110500}
{"episode_reward": 48.256770169580975, "episode": 885.0, "batch_reward": 1.3922175884246826, "critic_loss": 17.811036109924316, "actor_loss": -256.346435546875, "actor_target_entropy": -1.0, "actor_entropy": 0.39496682286262513, "alpha_loss": 0.009444725327193737, "alpha_value": 0.21980224506469695, "duration": 17.494402170181274, "step": 111000}
{"episode_reward": 73.82404319332291, "episode": 889.0, "batch_reward": 1.5466606855392455, "critic_loss": 21.361603927612304, "actor_loss": -257.7086486816406, "actor_target_entropy": -1.0, "actor_entropy": 0.34703636169433594, "alpha_loss": -0.011823715828359126, "alpha_value": 0.22069453623883728, "duration": 18.639411449432373, "step": 111500}
{"episode_reward": 34.5575785973615, "episode": 893.0, "batch_reward": 1.5502189636230468, "critic_loss": 16.481038665771486, "actor_loss": -257.9135681152344, "actor_target_entropy": -1.0, "actor_entropy": 0.34580249190330503, "alpha_loss": -0.0008318129926919937, "alpha_value": 0.2222669073915478, "duration": 35.36357402801514, "step": 112000}
{"episode_reward": 46.63795825433291, "episode": 897.0, "batch_reward": 1.441689395904541, "critic_loss": 21.724113845825194, "actor_loss": -258.23151245117185, "actor_target_entropy": -1.0, "actor_entropy": 0.3685880064964294, "alpha_loss": -0.005711279902607202, "alpha_value": 0.2221886642888229, "duration": 19.028929948806763, "step": 112500}
{"episode_reward": 48.38632951840874, "episode": 901.0, "batch_reward": 1.4715011835098266, "critic_loss": 22.629383277893066, "actor_loss": -259.27662353515626, "actor_target_entropy": -1.0, "actor_entropy": 0.39546645283699033, "alpha_loss": 0.011894007958471776, "alpha_value": 0.22220968779406386, "duration": 19.545417070388794, "step": 113000}
{"episode_reward": 55.93291843008403, "episode": 905.0, "batch_reward": 1.519702959060669, "critic_loss": 13.765195846557617, "actor_loss": -257.8479248046875, "actor_target_entropy": -1.0, "actor_entropy": 0.3820031523704529, "alpha_loss": 0.00910002961754799, "alpha_value": 0.22133252402605574, "duration": 30.36380124092102, "step": 113500}
{"episode_reward": 42.95060056684472, "episode": 909.0, "batch_reward": 1.4190421104431152, "critic_loss": 19.513936614990236, "actor_loss": -258.79555053710936, "actor_target_entropy": -1.0, "actor_entropy": 0.38256749510765076, "alpha_loss": -0.04123690836131573, "alpha_value": 0.22196303265398248, "duration": 23.754799842834473, "step": 114000}
{"episode_reward": 51.89365837799608, "episode": 913.0, "batch_reward": 1.4567986726760864, "critic_loss": 21.988086700439453, "actor_loss": -258.8708435058594, "actor_target_entropy": -1.0, "actor_entropy": 0.4203832745552063, "alpha_loss": 0.007019315846264362, "alpha_value": 0.22377480280919496, "duration": 19.094273567199707, "step": 114500}
{"episode_reward": 93.46215077742995, "episode": 917.0, "batch_reward": 1.5625906229019164, "critic_loss": 20.572036361694337, "actor_loss": -259.9077392578125, "actor_target_entropy": -1.0, "actor_entropy": 0.32741838693618774, "alpha_loss": -0.0006282282993197441, "alpha_value": 0.2230189206534837, "duration": 18.75251269340515, "step": 115000}
{"episode_reward": 60.187673817369564, "episode": 921.0, "batch_reward": 1.4186280012130736, "critic_loss": 17.0818151473999, "actor_loss": -259.2720031738281, "actor_target_entropy": -1.0, "actor_entropy": 0.36790251135826113, "alpha_loss": -0.039563007280230524, "alpha_value": 0.22275505458749612, "duration": 18.252933740615845, "step": 115500}
{"episode_reward": 31.688873899099022, "episode": 925.0, "batch_reward": 1.4865101814270019, "critic_loss": 23.805382537841798, "actor_loss": -260.5472045898438, "actor_target_entropy": -1.0, "actor_entropy": 0.3017475098371506, "alpha_loss": 0.02846031282097101, "alpha_value": 0.22316552737902629, "duration": 20.232505321502686, "step": 116000}
{"episode_reward": 56.621386361616786, "episode": 929.0, "batch_reward": 1.2681613445281983, "critic_loss": 21.02307834625244, "actor_loss": -261.1411865234375, "actor_target_entropy": -1.0, "actor_entropy": 0.3762634515762329, "alpha_loss": -0.016122226044535636, "alpha_value": 0.2229652718244199, "duration": 17.047687530517578, "step": 116500}
{"episode_reward": 178.57124242474373, "episode": 933.0, "batch_reward": 1.5605148315429687, "critic_loss": 21.661262893676756, "actor_loss": -261.6418395996094, "actor_target_entropy": -1.0, "actor_entropy": 0.36765484809875487, "alpha_loss": -0.025777026638388635, "alpha_value": 0.22263067989409385, "duration": 17.17842984199524, "step": 117000}
{"episode_reward": 54.4027588774068, "episode": 937.0, "batch_reward": 1.3365404605865479, "critic_loss": 15.813741302490234, "actor_loss": -259.9994873046875, "actor_target_entropy": -1.0, "actor_entropy": 0.39927205443382263, "alpha_loss": 0.0023206591606140135, "alpha_value": 0.22401144450136776, "duration": 17.700918197631836, "step": 117500}
{"episode_reward": 20.791974488864643, "episode": 941.0, "batch_reward": 1.402849268913269, "critic_loss": 19.89931688308716, "actor_loss": -260.6237487792969, "actor_target_entropy": -1.0, "actor_entropy": 0.4383052110671997, "alpha_loss": 0.023357325047254563, "alpha_value": 0.22298856563925415, "duration": 40.41761374473572, "step": 118000}
{"episode_reward": 68.6033474444241, "episode": 945.0, "batch_reward": 1.3361907005310059, "critic_loss": 19.05631103515625, "actor_loss": -261.9025634765625, "actor_target_entropy": -1.0, "actor_entropy": 0.4636682510375977, "alpha_loss": -0.006644195318222046, "alpha_value": 0.22324822784901496, "duration": 18.50133180618286, "step": 118500}
{"episode_reward": 62.57963582893784, "episode": 949.0, "batch_reward": 1.3750367879867553, "critic_loss": 17.140061378479004, "actor_loss": -262.35601196289065, "actor_target_entropy": -1.0, "actor_entropy": 0.4426477253437042, "alpha_loss": -0.006031197123229503, "alpha_value": 0.22540953614176856, "duration": 32.013625144958496, "step": 119000}
{"episode_reward": 64.33084033622667, "episode": 953.0, "batch_reward": 1.3629859209060669, "critic_loss": 15.226990509033204, "actor_loss": -262.3607604980469, "actor_target_entropy": -1.0, "actor_entropy": 0.43934525847434996, "alpha_loss": -0.01284702606499195, "alpha_value": 0.2264117040382514, "duration": 16.808952569961548, "step": 119500}
{"episode_reward": 51.965208276108605, "episode": 957.0, "batch_reward": 1.4744755506515503, "critic_loss": 14.273208045959473, "actor_loss": -262.4927001953125, "actor_target_entropy": -1.0, "actor_entropy": 0.3838434100151062, "alpha_loss": -0.010471654124557972, "alpha_value": 0.2257740801625682, "step": 120000}
{"duration": 32.58884835243225, "step": 120000}
{"episode_reward": 55.104638810439695, "episode": 961.0, "batch_reward": 1.480046796798706, "critic_loss": 16.53057689666748, "actor_loss": -262.85381469726565, "actor_target_entropy": -1.0, "actor_entropy": 0.43584195971488954, "alpha_loss": 0.007087358087301254, "alpha_value": 0.22559330458893762, "duration": 18.631001472473145, "step": 120500}
{"episode_reward": 30.94778245360496, "episode": 965.0, "batch_reward": 1.337645697593689, "critic_loss": 18.798678398132324, "actor_loss": -263.63129272460935, "actor_target_entropy": -1.0, "actor_entropy": 0.4679639220237732, "alpha_loss": -0.010500937793403864, "alpha_value": 0.22635817642184813, "duration": 21.26464080810547, "step": 121000}
{"episode_reward": 62.471997853990885, "episode": 969.0, "batch_reward": 1.3970795631408692, "critic_loss": 17.69168891906738, "actor_loss": -263.72398071289064, "actor_target_entropy": -1.0, "actor_entropy": 0.46554930210113527, "alpha_loss": -0.025150330364704133, "alpha_value": 0.2279869005461043, "duration": 38.72329044342041, "step": 121500}
{"episode_reward": 68.75386000161431, "episode": 973.0, "batch_reward": 1.3497975587844848, "critic_loss": 15.496402931213378, "actor_loss": -263.193896484375, "actor_target_entropy": -1.0, "actor_entropy": 0.4388570010662079, "alpha_loss": 0.012040198221802712, "alpha_value": 0.22936006636753453, "duration": 18.87549924850464, "step": 122000}
{"episode_reward": 31.98535555786725, "episode": 977.0, "batch_reward": 1.4513251781463623, "critic_loss": 15.293470764160157, "actor_loss": -263.5867858886719, "actor_target_entropy": -1.0, "actor_entropy": 0.4574318528175354, "alpha_loss": -0.0037586383521556856, "alpha_value": 0.23061701441995702, "duration": 19.161323070526123, "step": 122500}
{"episode_reward": 72.46818295328066, "episode": 981.0, "batch_reward": 1.335118055343628, "critic_loss": 15.96903018951416, "actor_loss": -263.8565612792969, "actor_target_entropy": -1.0, "actor_entropy": 0.47382362484931945, "alpha_loss": 0.0065000922419130806, "alpha_value": 0.2299894965984844, "duration": 20.72235345840454, "step": 123000}
{"episode_reward": 75.89543336890007, "episode": 985.0, "batch_reward": 1.3576244831085205, "critic_loss": 14.137384986877441, "actor_loss": -264.2819580078125, "actor_target_entropy": -1.0, "actor_entropy": 0.39483044147491453, "alpha_loss": 0.007730816211551428, "alpha_value": 0.22905412320095797, "duration": 16.556621551513672, "step": 123500}
{"episode_reward": 66.30947725253027, "episode": 989.0, "batch_reward": 1.3507731676101684, "critic_loss": 20.11060333251953, "actor_loss": -264.2067443847656, "actor_target_entropy": -1.0, "actor_entropy": 0.43074893951416016, "alpha_loss": -0.002839234098792076, "alpha_value": 0.22840672106012622, "duration": 17.47715401649475, "step": 124000}
{"episode_reward": 176.66479963217824, "episode": 993.0, "batch_reward": 1.356426739692688, "critic_loss": 18.933724021911623, "actor_loss": -265.0321472167969, "actor_target_entropy": -1.0, "actor_entropy": 0.4839304804801941, "alpha_loss": -0.01467644670046866, "alpha_value": 0.2303558348244265, "duration": 17.712340593338013, "step": 124500}
{"episode_reward": 58.12780886250283, "episode": 997.0, "batch_reward": 1.3161898612976075, "critic_loss": 16.010062408447265, "actor_loss": -264.3428161621094, "actor_target_entropy": -1.0, "actor_entropy": 0.46911486983299255, "alpha_loss": 0.01387990415096283, "alpha_value": 0.23125511108517074, "duration": 17.146093130111694, "step": 125000}
{"episode_reward": 72.04799760342841, "episode": 1001.0, "batch_reward": 1.4580290079116822, "critic_loss": 17.22381458282471, "actor_loss": -263.95604248046874, "actor_target_entropy": -1.0, "actor_entropy": 0.4787383794784546, "alpha_loss": 0.009701924212276936, "alpha_value": 0.2315236628929526, "duration": 16.90851092338562, "step": 125500}
{"episode_reward": 72.10120078137771, "episode": 1005.0, "batch_reward": 1.3698171377182007, "critic_loss": 17.705730438232422, "actor_loss": -265.25763549804685, "actor_target_entropy": -1.0, "actor_entropy": 0.4273399651050568, "alpha_loss": 0.00646152924746275, "alpha_value": 0.23196791785111653, "duration": 16.94014883041382, "step": 126000}
{"episode_reward": 129.8042036852154, "episode": 1009.0, "batch_reward": 1.3596307039260864, "critic_loss": 16.96582145690918, "actor_loss": -265.4783203125, "actor_target_entropy": -1.0, "actor_entropy": 0.5062387168407441, "alpha_loss": -0.02752148676663637, "alpha_value": 0.23348685366837488, "duration": 17.59423804283142, "step": 126500}
{"episode_reward": 65.45753845453399, "episode": 1013.0, "batch_reward": 1.306972336769104, "critic_loss": 18.382246208190917, "actor_loss": -266.50938110351564, "actor_target_entropy": -1.0, "actor_entropy": 0.5162479221820832, "alpha_loss": -0.034778882190585135, "alpha_value": 0.23453241714585, "duration": 15.903523683547974, "step": 127000}
{"episode_reward": 69.57889314745123, "episode": 1017.0, "batch_reward": 1.3413742542266847, "critic_loss": 16.559395790100098, "actor_loss": -266.85536499023436, "actor_target_entropy": -1.0, "actor_entropy": 0.5373628735542297, "alpha_loss": -0.03234019353985786, "alpha_value": 0.23800368670539643, "duration": 16.537994384765625, "step": 127500}
{"episode_reward": 56.35418281214146, "episode": 1021.0, "batch_reward": 1.3569197177886962, "critic_loss": 13.611120986938477, "actor_loss": -265.89991455078126, "actor_target_entropy": -1.0, "actor_entropy": 0.46112921833992004, "alpha_loss": 0.003815266489982605, "alpha_value": 0.2404150806518004, "duration": 17.689625024795532, "step": 128000}
{"episode_reward": 68.36993339967007, "episode": 1025.0, "batch_reward": 1.31724112033844, "critic_loss": 22.8051420211792, "actor_loss": -266.0591796875, "actor_target_entropy": -1.0, "actor_entropy": 0.4268417000770569, "alpha_loss": -0.025656091794371606, "alpha_value": 0.24151368158321368, "duration": 17.528761625289917, "step": 128500}
{"episode_reward": 285.77244751908586, "episode": 1029.0, "batch_reward": 1.3249354600906371, "critic_loss": 20.56524238586426, "actor_loss": -265.6490966796875, "actor_target_entropy": -1.0, "actor_entropy": 0.4794078290462494, "alpha_loss": -0.0006699865683913231, "alpha_value": 0.24333197033596346, "duration": 16.5571391582489, "step": 129000}
{"episode_reward": 46.902742968259865, "episode": 1033.0, "batch_reward": 1.3396806240081787, "critic_loss": 15.521829223632812, "actor_loss": -265.5122985839844, "actor_target_entropy": -1.0, "actor_entropy": 0.4771472096443176, "alpha_loss": 0.005642054975032807, "alpha_value": 0.24365034917537023, "duration": 17.61263346672058, "step": 129500}
{"episode_reward": 63.70023865268007, "episode": 1037.0, "batch_reward": 1.1595399975776672, "critic_loss": 19.19852981567383, "actor_loss": -265.69334106445314, "actor_target_entropy": -1.0, "actor_entropy": 0.5144335806369782, "alpha_loss": -0.00811690278351307, "alpha_value": 0.24404949242196933, "step": 130000}
{"duration": 32.73678112030029, "step": 130000}
{"episode_reward": 72.60205406806543, "episode": 1041.0, "batch_reward": 1.261308193206787, "critic_loss": 13.18870735168457, "actor_loss": -266.78362426757815, "actor_target_entropy": -1.0, "actor_entropy": 0.5136146426200867, "alpha_loss": 0.012958323303610086, "alpha_value": 0.24542435387154624, "duration": 16.675676584243774, "step": 130500}
{"episode_reward": 54.31298034194366, "episode": 1045.0, "batch_reward": 1.2863510847091675, "critic_loss": 16.04447650909424, "actor_loss": -267.27728881835935, "actor_target_entropy": -1.0, "actor_entropy": 0.5212278604507447, "alpha_loss": -0.0029073134064674377, "alpha_value": 0.2453917547857424, "duration": 18.091206550598145, "step": 131000}
{"episode_reward": 219.614292774423, "episode": 1049.0, "batch_reward": 1.2862373828887939, "critic_loss": 16.396918487548827, "actor_loss": -267.7835388183594, "actor_target_entropy": -1.0, "actor_entropy": 0.4981850624084473, "alpha_loss": 0.01857720036059618, "alpha_value": 0.24496865953327102, "duration": 18.422272443771362, "step": 131500}
{"episode_reward": 269.43102476147817, "episode": 1053.0, "batch_reward": 1.1866111040115357, "critic_loss": 17.36385097503662, "actor_loss": -266.8597412109375, "actor_target_entropy": -1.0, "actor_entropy": 0.5476751446723938, "alpha_loss": -0.02209073379635811, "alpha_value": 0.24466751485561117, "duration": 32.42800235748291, "step": 132000}
{"episode_reward": 44.07446217661458, "episode": 1057.0, "batch_reward": 1.2828346014022827, "critic_loss": 15.179665756225585, "actor_loss": -267.1706970214844, "actor_target_entropy": -1.0, "actor_entropy": 0.5167923331260681, "alpha_loss": -0.007736505195498467, "alpha_value": 0.24578858047933588, "duration": 20.037885427474976, "step": 132500}
{"episode_reward": 72.0939970831795, "episode": 1061.0, "batch_reward": 1.3372782468795776, "critic_loss": 13.62943229675293, "actor_loss": -267.5144348144531, "actor_target_entropy": -1.0, "actor_entropy": 0.5858767867088318, "alpha_loss": 0.0010341163724660873, "alpha_value": 0.24832598023332783, "duration": 17.92963671684265, "step": 133000}
{"episode_reward": 166.38624962996138, "episode": 1065.0, "batch_reward": 1.2495700359344482, "critic_loss": 16.475947189331055, "actor_loss": -267.6969787597656, "actor_target_entropy": -1.0, "actor_entropy": 0.5257810235023499, "alpha_loss": 0.014726231060922145, "alpha_value": 0.2505231137049397, "duration": 18.213027238845825, "step": 133500}
{"episode_reward": 52.45766282444429, "episode": 1069.0, "batch_reward": 1.233432412147522, "critic_loss": 14.62083396911621, "actor_loss": -268.25302734375, "actor_target_entropy": -1.0, "actor_entropy": 0.5060672342777253, "alpha_loss": -0.010454892460256816, "alpha_value": 0.2508811825715125, "duration": 21.56720733642578, "step": 134000}
{"episode_reward": 58.655712366206636, "episode": 1073.0, "batch_reward": 1.2254111528396607, "critic_loss": 14.716532135009766, "actor_loss": -267.5895263671875, "actor_target_entropy": -1.0, "actor_entropy": 0.48707873225212095, "alpha_loss": 0.015363197028636932, "alpha_value": 0.25073449584038604, "duration": 18.98432159423828, "step": 134500}
{"episode_reward": 181.7402178230535, "episode": 1077.0, "batch_reward": 1.1636839866638184, "critic_loss": 15.804841613769531, "actor_loss": -267.81113891601564, "actor_target_entropy": -1.0, "actor_entropy": 0.5222385227680206, "alpha_loss": -0.028770857583731414, "alpha_value": 0.25060534169603216, "duration": 20.92198944091797, "step": 135000}
{"episode_reward": 200.7719599210269, "episode": 1081.0, "batch_reward": 1.2537235736846923, "critic_loss": 17.02022819519043, "actor_loss": -268.52684326171874, "actor_target_entropy": -1.0, "actor_entropy": 0.5314632177352905, "alpha_loss": 0.021801208704710008, "alpha_value": 0.2503212546062103, "duration": 19.276644706726074, "step": 135500}
{"episode_reward": 121.28634244914241, "episode": 1085.0, "batch_reward": 1.2337295055389403, "critic_loss": 12.016110229492188, "actor_loss": -267.6846435546875, "actor_target_entropy": -1.0, "actor_entropy": 0.5406017541885376, "alpha_loss": 0.004265465401113033, "alpha_value": 0.2485315636777004, "duration": 17.718125581741333, "step": 136000}
{"episode_reward": 103.37255609451435, "episode": 1089.0, "batch_reward": 1.2820322036743164, "critic_loss": 16.224545097351076, "actor_loss": -268.4416931152344, "actor_target_entropy": -1.0, "actor_entropy": 0.5477993726730347, "alpha_loss": -0.002394304424524307, "alpha_value": 0.24994817491834914, "duration": 16.733633995056152, "step": 136500}
{"episode_reward": 182.36924113937954, "episode": 1093.0, "batch_reward": 1.369428825378418, "critic_loss": 10.398565101623536, "actor_loss": -268.2760009765625, "actor_target_entropy": -1.0, "actor_entropy": 0.5837841868400574, "alpha_loss": 0.023050899244844915, "alpha_value": 0.2504067403396332, "duration": 31.947998523712158, "step": 137000}
{"episode_reward": 212.40014942224187, "episode": 1097.0, "batch_reward": 1.1456051111221313, "critic_loss": 12.493973922729491, "actor_loss": -268.30690307617186, "actor_target_entropy": -1.0, "actor_entropy": 0.45623388290405276, "alpha_loss": 0.002484145574271679, "alpha_value": 0.2514460813792439, "duration": 18.92971396446228, "step": 137500}
{"episode_reward": 220.1372311583246, "episode": 1101.0, "batch_reward": 1.2754181146621704, "critic_loss": 14.291024780273437, "actor_loss": -268.6210021972656, "actor_target_entropy": -1.0, "actor_entropy": 0.5562126040458679, "alpha_loss": -0.009765084832906723, "alpha_value": 0.25304253447706737, "duration": 18.7276930809021, "step": 138000}
{"episode_reward": 48.11846007131293, "episode": 1105.0, "batch_reward": 1.2375113487243652, "critic_loss": 18.47397689819336, "actor_loss": -268.5149291992187, "actor_target_entropy": -1.0, "actor_entropy": 0.5179409682750702, "alpha_loss": 0.02900972291827202, "alpha_value": 0.25214017525253535, "duration": 16.360812425613403, "step": 138500}
{"episode_reward": 137.9863674910748, "episode": 1109.0, "batch_reward": 1.1693161129951477, "critic_loss": 17.116611289978028, "actor_loss": -267.7557006835938, "actor_target_entropy": -1.0, "actor_entropy": 0.4738158345222473, "alpha_loss": -0.017108561098575593, "alpha_value": 0.2511329305987901, "duration": 16.980312824249268, "step": 139000}
{"episode_reward": 160.07311266404926, "episode": 1113.0, "batch_reward": 1.1309031248092651, "critic_loss": 14.661759567260741, "actor_loss": -268.48289794921874, "actor_target_entropy": -1.0, "actor_entropy": 0.518715888261795, "alpha_loss": -0.011065979581326246, "alpha_value": 0.25010970359661466, "duration": 33.41567587852478, "step": 139500}
{"episode_reward": 224.27837780210908, "episode": 1117.0, "batch_reward": 1.1382630586624145, "critic_loss": 15.459355354309082, "actor_loss": -268.23186645507815, "actor_target_entropy": -1.0, "actor_entropy": 0.5114474952220917, "alpha_loss": -0.008923448622226715, "alpha_value": 0.2506222853446253, "step": 140000}
{"duration": 33.429075479507446, "step": 140000}
{"episode_reward": 209.44511302531507, "episode": 1121.0, "batch_reward": 1.2227511882781983, "critic_loss": 13.318514919281006, "actor_loss": -268.5158630371094, "actor_target_entropy": -1.0, "actor_entropy": 0.5196101367473602, "alpha_loss": -0.0075779294595122336, "alpha_value": 0.251618082941076, "duration": 18.57052493095398, "step": 140500}
{"episode_reward": 185.78670294137234, "episode": 1125.0, "batch_reward": 1.1673194408416747, "critic_loss": 14.879885864257812, "actor_loss": -268.4928466796875, "actor_target_entropy": -1.0, "actor_entropy": 0.5475770831108093, "alpha_loss": -0.01934270290657878, "alpha_value": 0.25284155996041185, "duration": 17.71642565727234, "step": 141000}
{"episode_reward": 247.41791011468712, "episode": 1129.0, "batch_reward": 1.131548571586609, "critic_loss": 13.776172256469726, "actor_loss": -268.3269287109375, "actor_target_entropy": -1.0, "actor_entropy": 0.5759099245071411, "alpha_loss": -0.014631503727287054, "alpha_value": 0.2531419700611549, "duration": 20.83340287208557, "step": 141500}
{"episode_reward": 229.2240262126587, "episode": 1133.0, "batch_reward": 1.3362435340881347, "critic_loss": 17.98340015411377, "actor_loss": -269.6381408691406, "actor_target_entropy": -1.0, "actor_entropy": 0.48545621037483216, "alpha_loss": -0.002302340045571327, "alpha_value": 0.2558755584911202, "duration": 16.327913284301758, "step": 142000}
{"episode_reward": 296.20194682669677, "episode": 1137.0, "batch_reward": 1.0682237267494201, "critic_loss": 18.010462951660156, "actor_loss": -269.90623779296874, "actor_target_entropy": -1.0, "actor_entropy": 0.5645196080207825, "alpha_loss": -0.03252817951142788, "alpha_value": 0.25802816327831446, "duration": 18.79122257232666, "step": 142500}
{"episode_reward": 183.9932746922531, "episode": 1141.0, "batch_reward": 1.2092112064361573, "critic_loss": 17.341478157043458, "actor_loss": -269.3134765625, "actor_target_entropy": -1.0, "actor_entropy": 0.5546833395957946, "alpha_loss": 0.008329073898494244, "alpha_value": 0.26036379026830175, "duration": 16.83705163002014, "step": 143000}
{"episode_reward": 203.1630661290912, "episode": 1145.0, "batch_reward": 1.0689867734909058, "critic_loss": 12.382369422912598, "actor_loss": -268.8240112304687, "actor_target_entropy": -1.0, "actor_entropy": 0.544095641374588, "alpha_loss": -0.009024137910455466, "alpha_value": 0.2606688124344075, "duration": 19.49511194229126, "step": 143500}
{"episode_reward": 342.7472587589469, "episode": 1149.0, "batch_reward": 1.144594097137451, "critic_loss": 12.976375389099122, "actor_loss": -268.97645263671876, "actor_target_entropy": -1.0, "actor_entropy": 0.5486388802528381, "alpha_loss": 0.002147870510816574, "alpha_value": 0.2603366241376598, "duration": 16.235620260238647, "step": 144000}
{"episode_reward": 66.2757955764561, "episode": 1153.0, "batch_reward": 1.134694242477417, "critic_loss": 14.788150787353516, "actor_loss": -269.27410278320315, "actor_target_entropy": -1.0, "actor_entropy": 0.48203396797180176, "alpha_loss": -0.0058054253458976746, "alpha_value": 0.2605041575745222, "duration": 21.35370898246765, "step": 144500}
{"episode_reward": 75.26236692998316, "episode": 1157.0, "batch_reward": 1.1411548614501954, "critic_loss": 17.959499549865722, "actor_loss": -269.6633361816406, "actor_target_entropy": -1.0, "actor_entropy": 0.5832454562187195, "alpha_loss": 0.01017884500324726, "alpha_value": 0.26060339157872636, "duration": 15.762972354888916, "step": 145000}
{"episode_reward": 66.68993920596554, "episode": 1161.0, "batch_reward": 1.26856369972229, "critic_loss": 13.866291046142578, "actor_loss": -269.00279541015624, "actor_target_entropy": -1.0, "actor_entropy": 0.5454559445381164, "alpha_loss": 0.0034734126180410384, "alpha_value": 0.2605755242658375, "duration": 35.66275763511658, "step": 145500}
{"episode_reward": 124.36085297496928, "episode": 1165.0, "batch_reward": 1.230960202217102, "critic_loss": 14.636932945251464, "actor_loss": -268.72202758789064, "actor_target_entropy": -1.0, "actor_entropy": 0.5744760632514954, "alpha_loss": -0.01598946563899517, "alpha_value": 0.26248006020461634, "duration": 18.237719297409058, "step": 146000}
{"episode_reward": 62.29553129717783, "episode": 1169.0, "batch_reward": 1.1648293256759643, "critic_loss": 12.491754913330078, "actor_loss": -269.8173889160156, "actor_target_entropy": -1.0, "actor_entropy": 0.5655542731285095, "alpha_loss": -0.01927141975611448, "alpha_value": 0.26330846112903766, "duration": 21.78746509552002, "step": 146500}
{"episode_reward": 181.9695229783485, "episode": 1173.0, "batch_reward": 1.2495160818099975, "critic_loss": 12.208384895324707, "actor_loss": -268.3231689453125, "actor_target_entropy": -1.0, "actor_entropy": 0.5651718854904175, "alpha_loss": 0.007711436599493027, "alpha_value": 0.2633630399589265, "duration": 17.979066610336304, "step": 147000}
{"episode_reward": 266.3716972598477, "episode": 1177.0, "batch_reward": 1.1416754245758056, "critic_loss": 14.80686550140381, "actor_loss": -268.8906677246094, "actor_target_entropy": -1.0, "actor_entropy": 0.5664645850658416, "alpha_loss": -0.03148388378322124, "alpha_value": 0.26462806641811315, "duration": 18.97884511947632, "step": 147500}
{"episode_reward": 205.4466030719268, "episode": 1181.0, "batch_reward": 1.2171497106552125, "critic_loss": 14.186230850219726, "actor_loss": -268.3730224609375, "actor_target_entropy": -1.0, "actor_entropy": 0.6162250399589538, "alpha_loss": 0.012497136928141117, "alpha_value": 0.2658351882037853, "duration": 20.47514247894287, "step": 148000}
{"episode_reward": 326.20201714218064, "episode": 1185.0, "batch_reward": 1.0607966542243958, "critic_loss": 15.578598976135254, "actor_loss": -268.41187744140626, "actor_target_entropy": -1.0, "actor_entropy": 0.5168177604675293, "alpha_loss": -0.012917608581483364, "alpha_value": 0.26442221774527186, "duration": 19.055156230926514, "step": 148500}
{"episode_reward": 243.52928597744238, "episode": 1189.0, "batch_reward": 1.1040367841720582, "critic_loss": 12.5193021774292, "actor_loss": -268.4654052734375, "actor_target_entropy": -1.0, "actor_entropy": 0.6077786445617676, "alpha_loss": 0.047013582475483415, "alpha_value": 0.26446634035496086, "duration": 18.348124980926514, "step": 149000}
{"episode_reward": 257.42605519971335, "episode": 1193.0, "batch_reward": 1.2555907249450684, "critic_loss": 11.982791709899903, "actor_loss": -268.789697265625, "actor_target_entropy": -1.0, "actor_entropy": 0.5512358784675598, "alpha_loss": 0.008988999389111995, "alpha_value": 0.2632328788988615, "duration": 16.80854082107544, "step": 149500}
{"episode_reward": 251.1445633111588, "episode": 1197.0, "batch_reward": 1.2701526165008545, "critic_loss": 16.218363571166993, "actor_loss": -267.9072509765625, "actor_target_entropy": -1.0, "actor_entropy": 0.5667264401912689, "alpha_loss": -0.02492036186158657, "alpha_value": 0.2626581781335132, "step": 150000}
{"duration": 37.48038387298584, "step": 150000}
{"episode_reward": 259.1782731058228, "episode": 1201.0, "batch_reward": 1.1977130889892578, "critic_loss": 12.989348030090332, "actor_loss": -268.06394653320314, "actor_target_entropy": -1.0, "actor_entropy": 0.5653599739074707, "alpha_loss": 0.03597007393836975, "alpha_value": 0.26388310866569575, "duration": 16.42852783203125, "step": 150500}
{"episode_reward": 114.12675691653472, "episode": 1205.0, "batch_reward": 1.293069338798523, "critic_loss": 14.2392147064209, "actor_loss": -268.18825073242186, "actor_target_entropy": -1.0, "actor_entropy": 0.5308414041996002, "alpha_loss": 0.00019523296505212783, "alpha_value": 0.2642101251527035, "duration": 16.268309354782104, "step": 151000}
{"episode_reward": 191.18272483888367, "episode": 1209.0, "batch_reward": 1.2054409980773926, "critic_loss": 11.212543487548828, "actor_loss": -267.368310546875, "actor_target_entropy": -1.0, "actor_entropy": 0.5676045060157776, "alpha_loss": 0.031697165593504904, "alpha_value": 0.262627318446916, "duration": 17.0918231010437, "step": 151500}
{"episode_reward": 25.464654616527156, "episode": 1213.0, "batch_reward": 1.0643754482269288, "critic_loss": 11.92510814666748, "actor_loss": -268.0808959960938, "actor_target_entropy": -1.0, "actor_entropy": 0.5406815409660339, "alpha_loss": -0.033928364887833594, "alpha_value": 0.26114134826053814, "duration": 19.37297534942627, "step": 152000}
{"episode_reward": 29.768866966993947, "episode": 1217.0, "batch_reward": 1.1469041109085083, "critic_loss": 12.62548894882202, "actor_loss": -267.8788330078125, "actor_target_entropy": -1.0, "actor_entropy": 0.5855265974998474, "alpha_loss": -0.03620599266141653, "alpha_value": 0.26282003498936435, "duration": 17.513347387313843, "step": 152500}
{"episode_reward": 47.038483485581, "episode": 1221.0, "batch_reward": 1.156016993522644, "critic_loss": 11.963807296752929, "actor_loss": -266.28749389648436, "actor_target_entropy": -1.0, "actor_entropy": 0.5972419261932373, "alpha_loss": -0.02866776715964079, "alpha_value": 0.26527975088883954, "duration": 16.380574464797974, "step": 153000}
{"episode_reward": 46.60146350491979, "episode": 1225.0, "batch_reward": 1.1700164556503296, "critic_loss": 13.482058906555176, "actor_loss": -267.433984375, "actor_target_entropy": -1.0, "actor_entropy": 0.6037543892860413, "alpha_loss": -0.027711547911167145, "alpha_value": 0.26814158193954063, "duration": 15.840470790863037, "step": 153500}
{"episode_reward": 62.216943008772056, "episode": 1229.0, "batch_reward": 1.2026217937469483, "critic_loss": 13.17902431488037, "actor_loss": -267.6685791015625, "actor_target_entropy": -1.0, "actor_entropy": 0.6115245461463928, "alpha_loss": -0.011669915542006493, "alpha_value": 0.2696630969348768, "duration": 17.823896884918213, "step": 154000}
{"episode_reward": 23.75084467879314, "episode": 1233.0, "batch_reward": 1.179654026031494, "critic_loss": 15.094990158081055, "actor_loss": -266.92890014648435, "actor_target_entropy": -1.0, "actor_entropy": 0.5958364367485046, "alpha_loss": 0.018037772551178933, "alpha_value": 0.2709010412480784, "duration": 20.008282899856567, "step": 154500}
{"episode_reward": 103.23118662893377, "episode": 1237.0, "batch_reward": 1.068637204170227, "critic_loss": 13.873860168457032, "actor_loss": -266.40498046875, "actor_target_entropy": -1.0, "actor_entropy": 0.547496235370636, "alpha_loss": 0.020568506419658662, "alpha_value": 0.2718289464445992, "duration": 16.789295196533203, "step": 155000}
{"episode_reward": 55.25554380772587, "episode": 1241.0, "batch_reward": 1.092811918258667, "critic_loss": 12.352048110961913, "actor_loss": -266.384130859375, "actor_target_entropy": -1.0, "actor_entropy": 0.5745033502578736, "alpha_loss": 0.012260203808546066, "alpha_value": 0.2710522823872398, "duration": 17.331241130828857, "step": 155500}
{"episode_reward": 54.30507133271222, "episode": 1245.0, "batch_reward": 1.1123912334442139, "critic_loss": 8.883062553405761, "actor_loss": -266.24082641601564, "actor_target_entropy": -1.0, "actor_entropy": 0.5712635278701782, "alpha_loss": -0.00223973635584116, "alpha_value": 0.2703237746671901, "duration": 18.09778380393982, "step": 156000}
{"episode_reward": 47.98495315053034, "episode": 1249.0, "batch_reward": 1.1550804376602173, "critic_loss": 12.558539390563965, "actor_loss": -266.58636474609375, "actor_target_entropy": -1.0, "actor_entropy": 0.5512208104133606, "alpha_loss": -0.003174612112343311, "alpha_value": 0.27065808629953314, "duration": 15.563596248626709, "step": 156500}
{"episode_reward": 36.22813801868654, "episode": 1253.0, "batch_reward": 1.0718178749084473, "critic_loss": 12.271017074584961, "actor_loss": -265.1067626953125, "actor_target_entropy": -1.0, "actor_entropy": 0.5985297083854675, "alpha_loss": 0.022197932377457617, "alpha_value": 0.27085938886955463, "duration": 17.1439151763916, "step": 157000}
{"episode_reward": 192.18905287346013, "episode": 1257.0, "batch_reward": 1.057310163974762, "critic_loss": 15.06962718963623, "actor_loss": -266.5864562988281, "actor_target_entropy": -1.0, "actor_entropy": 0.5675391674041748, "alpha_loss": -0.02466871440410614, "alpha_value": 0.27229094171744994, "duration": 16.368541717529297, "step": 157500}
{"episode_reward": 40.87012299440808, "episode": 1261.0, "batch_reward": 1.0956768989562988, "critic_loss": 14.167167663574219, "actor_loss": -266.0902526855469, "actor_target_entropy": -1.0, "actor_entropy": 0.5847355544567108, "alpha_loss": 0.019305350631475447, "alpha_value": 0.27491303912050424, "duration": 19.311548233032227, "step": 158000}
{"episode_reward": 70.74041214191008, "episode": 1265.0, "batch_reward": 1.0678561210632325, "critic_loss": 12.524530792236328, "actor_loss": -266.14796752929686, "actor_target_entropy": -1.0, "actor_entropy": 0.6192274808883667, "alpha_loss": -0.018611809890717267, "alpha_value": 0.2782399970739251, "duration": 18.16417360305786, "step": 158500}
{"episode_reward": 56.89181081792929, "episode": 1269.0, "batch_reward": 1.1358546018600464, "critic_loss": 10.746446800231933, "actor_loss": -266.64873657226565, "actor_target_entropy": -1.0, "actor_entropy": 0.5834737241268158, "alpha_loss": -0.011615664511919022, "alpha_value": 0.2816098187216363, "duration": 19.554280996322632, "step": 159000}
{"episode_reward": 48.51467151832304, "episode": 1273.0, "batch_reward": 1.066318190097809, "critic_loss": 11.028665828704835, "actor_loss": -265.83525390625, "actor_target_entropy": -1.0, "actor_entropy": 0.6198785185813904, "alpha_loss": -0.007857601344585418, "alpha_value": 0.2854908004501171, "duration": 22.065603494644165, "step": 159500}
{"episode_reward": 67.79650117095332, "episode": 1277.0, "batch_reward": 1.054546022415161, "critic_loss": 10.89439935684204, "actor_loss": -265.8267822265625, "actor_target_entropy": -1.0, "actor_entropy": 0.5650243997573853, "alpha_loss": -0.010653830599039793, "alpha_value": 0.2900537221192825, "step": 160000}
{"duration": 39.221232175827026, "step": 160000}
{"episode_reward": 41.398344671690346, "episode": 1281.0, "batch_reward": 1.1425281047821045, "critic_loss": 12.120453071594238, "actor_loss": -266.7155395507813, "actor_target_entropy": -1.0, "actor_entropy": 0.5809784770011902, "alpha_loss": 0.02912696860730648, "alpha_value": 0.2923804155384371, "duration": 21.677634477615356, "step": 160500}
{"episode_reward": 42.56443121893252, "episode": 1285.0, "batch_reward": 1.0867862820625305, "critic_loss": 13.883465003967284, "actor_loss": -267.5671630859375, "actor_target_entropy": -1.0, "actor_entropy": 0.6089624166488647, "alpha_loss": -0.04300437718629837, "alpha_value": 0.29468958452993566, "duration": 20.6127028465271, "step": 161000}
{"episode_reward": 198.87590742898968, "episode": 1289.0, "batch_reward": 1.0108978748321533, "critic_loss": 12.236267280578613, "actor_loss": -267.391357421875, "actor_target_entropy": -1.0, "actor_entropy": 0.6265304088592529, "alpha_loss": -0.006848888471722603, "alpha_value": 0.2973251800565885, "duration": 19.075735330581665, "step": 161500}
{"episode_reward": 77.42862324521603, "episode": 1293.0, "batch_reward": 1.1128505706787108, "critic_loss": 11.777598762512207, "actor_loss": -266.87318115234376, "actor_target_entropy": -1.0, "actor_entropy": 0.609811007976532, "alpha_loss": -0.0002912137657403946, "alpha_value": 0.2981931105172253, "duration": 16.961820363998413, "step": 162000}
{"episode_reward": 52.063060161215844, "episode": 1297.0, "batch_reward": 1.0433228015899658, "critic_loss": 11.78906021118164, "actor_loss": -266.3853393554688, "actor_target_entropy": -1.0, "actor_entropy": 0.6478458166122436, "alpha_loss": -0.0037053771317005157, "alpha_value": 0.2995939657799019, "duration": 21.048536777496338, "step": 162500}
{"episode_reward": 36.4367863965369, "episode": 1301.0, "batch_reward": 1.1038124322891236, "critic_loss": 11.954791259765624, "actor_loss": -267.2287902832031, "actor_target_entropy": -1.0, "actor_entropy": 0.6315062165260314, "alpha_loss": 0.009371098317205905, "alpha_value": 0.3001426729830846, "duration": 16.730647563934326, "step": 163000}
{"episode_reward": 21.87528277915408, "episode": 1305.0, "batch_reward": 1.04083594083786, "critic_loss": 11.131088638305664, "actor_loss": -267.8313232421875, "actor_target_entropy": -1.0, "actor_entropy": 0.6386990308761596, "alpha_loss": -0.019077051803469657, "alpha_value": 0.3013557168256899, "duration": 17.454880237579346, "step": 163500}
{"episode_reward": 59.032881402622266, "episode": 1309.0, "batch_reward": 1.0231910467147827, "critic_loss": 12.58740177154541, "actor_loss": -267.2240051269531, "actor_target_entropy": -1.0, "actor_entropy": 0.6253467440605164, "alpha_loss": -0.013816330209374427, "alpha_value": 0.30285679995679937, "duration": 38.64074349403381, "step": 164000}
{"episode_reward": 27.020852072738318, "episode": 1313.0, "batch_reward": 1.0195021033287048, "critic_loss": 12.319268226623535, "actor_loss": -266.8679138183594, "actor_target_entropy": -1.0, "actor_entropy": 0.6198384523391723, "alpha_loss": 0.015135176479816437, "alpha_value": 0.3054291043374295, "duration": 34.0423104763031, "step": 164500}
{"episode_reward": 70.63310353863645, "episode": 1317.0, "batch_reward": 1.0617642760276795, "critic_loss": 13.21139497756958, "actor_loss": -267.9890991210938, "actor_target_entropy": -1.0, "actor_entropy": 0.5921649932861328, "alpha_loss": -0.024557629972696303, "alpha_value": 0.30692652048650343, "duration": 22.58760714530945, "step": 165000}
{"episode_reward": 64.33576019436045, "episode": 1321.0, "batch_reward": 1.0690392136573792, "critic_loss": 12.442033958435058, "actor_loss": -268.6381530761719, "actor_target_entropy": -1.0, "actor_entropy": 0.6227115392684937, "alpha_loss": -0.005774819105863571, "alpha_value": 0.30822248864204643, "duration": 22.87127947807312, "step": 165500}
{"episode_reward": 74.31807126478056, "episode": 1325.0, "batch_reward": 0.9538614749908447, "critic_loss": 9.746945762634278, "actor_loss": -267.681884765625, "actor_target_entropy": -1.0, "actor_entropy": 0.5920181155204773, "alpha_loss": 0.003254932537674904, "alpha_value": 0.3085309333948694, "duration": 18.013217210769653, "step": 166000}
{"episode_reward": 107.7238196606806, "episode": 1329.0, "batch_reward": 0.9555828690528869, "critic_loss": 10.287884330749511, "actor_loss": -267.20794677734375, "actor_target_entropy": -1.0, "actor_entropy": 0.6663800477981567, "alpha_loss": -0.008938874676823616, "alpha_value": 0.3099837865902778, "duration": 15.957856178283691, "step": 166500}
{"episode_reward": 26.82553988348738, "episode": 1333.0, "batch_reward": 0.9294551730155944, "critic_loss": 12.229897499084473, "actor_loss": -267.585107421875, "actor_target_entropy": -1.0, "actor_entropy": 0.6145923018455506, "alpha_loss": 0.017977854423224925, "alpha_value": 0.31085496999251205, "duration": 17.780738353729248, "step": 167000}
{"episode_reward": 195.60862302726642, "episode": 1337.0, "batch_reward": 1.0060172200202941, "critic_loss": 11.529712867736816, "actor_loss": -268.78258056640624, "actor_target_entropy": -1.0, "actor_entropy": 0.6044377088546753, "alpha_loss": 0.0005908507853746414, "alpha_value": 0.3101364254462151, "duration": 17.58428430557251, "step": 167500}
{"episode_reward": 90.61538429940666, "episode": 1341.0, "batch_reward": 1.0009397745132447, "critic_loss": 13.000566482543945, "actor_loss": -268.11936645507814, "actor_target_entropy": -1.0, "actor_entropy": 0.6047667622566223, "alpha_loss": -0.011017928831279278, "alpha_value": 0.31004201633343614, "duration": 30.512697458267212, "step": 168000}
{"episode_reward": 62.31363094709581, "episode": 1345.0, "batch_reward": 0.893428897857666, "critic_loss": 11.633117866516113, "actor_loss": -267.67308349609374, "actor_target_entropy": -1.0, "actor_entropy": 0.6410877227783203, "alpha_loss": 0.0001107003539800644, "alpha_value": 0.3093184874175138, "duration": 16.904863595962524, "step": 168500}
{"episode_reward": 63.61765078721211, "episode": 1349.0, "batch_reward": 0.9429410934448242, "critic_loss": 10.93824577331543, "actor_loss": -267.49403076171876, "actor_target_entropy": -1.0, "actor_entropy": 0.584358811378479, "alpha_loss": 0.004319017753005028, "alpha_value": 0.30951026966295264, "duration": 17.980335235595703, "step": 169000}
{"episode_reward": 139.9383614012811, "episode": 1353.0, "batch_reward": 0.9341114282608032, "critic_loss": 10.045855903625489, "actor_loss": -268.50299072265625, "actor_target_entropy": -1.0, "actor_entropy": 0.6239720582962036, "alpha_loss": 0.010334466025233269, "alpha_value": 0.31078325220598635, "duration": 34.19185256958008, "step": 169500}
{"episode_reward": 56.90325411963786, "episode": 1357.0, "batch_reward": 0.9703224062919616, "critic_loss": 12.650287246704101, "actor_loss": -269.34217529296876, "actor_target_entropy": -1.0, "actor_entropy": 0.5989534735679627, "alpha_loss": -0.02440188005566597, "alpha_value": 0.31236047067919637, "step": 170000}
{"duration": 34.312195777893066, "step": 170000}
{"episode_reward": 54.01751930314772, "episode": 1361.0, "batch_reward": 0.8984901070594787, "critic_loss": 12.221263313293457, "actor_loss": -269.10009765625, "actor_target_entropy": -1.0, "actor_entropy": 0.6653855800628662, "alpha_loss": -0.011004550009965896, "alpha_value": 0.31393138133894155, "duration": 22.98493456840515, "step": 170500}
{"episode_reward": 55.71780089170113, "episode": 1365.0, "batch_reward": 0.932402241230011, "critic_loss": 12.294197273254394, "actor_loss": -268.7842224121094, "actor_target_entropy": -1.0, "actor_entropy": 0.5817773461341857, "alpha_loss": -0.018110906705260277, "alpha_value": 0.3151155252347858, "duration": 14.31688117980957, "step": 171000}
{"episode_reward": 48.678902493280944, "episode": 1369.0, "batch_reward": 0.8991491079330445, "critic_loss": 13.596580505371094, "actor_loss": -270.13148803710936, "actor_target_entropy": -1.0, "actor_entropy": 0.604470956325531, "alpha_loss": 0.0001301230862736702, "alpha_value": 0.3174355800188858, "duration": 16.630671977996826, "step": 171500}
{"episode_reward": 38.05289270526109, "episode": 1373.0, "batch_reward": 0.9550166249275207, "critic_loss": 14.78735179901123, "actor_loss": -270.5183532714844, "actor_target_entropy": -1.0, "actor_entropy": 0.5999971866607666, "alpha_loss": 0.02013704553246498, "alpha_value": 0.3195958295220144, "duration": 16.296106576919556, "step": 172000}
{"episode_reward": 44.45624976350485, "episode": 1377.0, "batch_reward": 0.941773784160614, "critic_loss": 10.627432441711425, "actor_loss": -270.3381286621094, "actor_target_entropy": -1.0, "actor_entropy": 0.5870850324630738, "alpha_loss": -0.0005509525537490845, "alpha_value": 0.3201778581990387, "duration": 16.744447469711304, "step": 172500}
{"episode_reward": 49.18099953820938, "episode": 1381.0, "batch_reward": 0.8500095844268799, "critic_loss": 9.654575729370118, "actor_loss": -270.3590393066406, "actor_target_entropy": -1.0, "actor_entropy": 0.6541940569877625, "alpha_loss": -0.023686683177947997, "alpha_value": 0.3205818392968047, "duration": 17.651131868362427, "step": 173000}
{"episode_reward": 76.21567623859536, "episode": 1385.0, "batch_reward": 0.7958707213401794, "critic_loss": 10.988310050964355, "actor_loss": -270.25096435546874, "actor_target_entropy": -1.0, "actor_entropy": 0.600536584854126, "alpha_loss": 0.0011154429987072945, "alpha_value": 0.3194453916951439, "duration": 16.79688787460327, "step": 173500}
{"episode_reward": 52.48290672437449, "episode": 1389.0, "batch_reward": 0.8649464845657349, "critic_loss": 11.884763526916505, "actor_loss": -269.98341674804686, "actor_target_entropy": -1.0, "actor_entropy": 0.6290115594863892, "alpha_loss": 0.008232732489705085, "alpha_value": 0.3188025364018438, "duration": 17.496403694152832, "step": 174000}
{"episode_reward": 185.02656057923969, "episode": 1393.0, "batch_reward": 0.8011597633361817, "critic_loss": 10.934338760375976, "actor_loss": -270.4302978515625, "actor_target_entropy": -1.0, "actor_entropy": 0.6489745736122131, "alpha_loss": -0.023834482207894324, "alpha_value": 0.3190492657466698, "duration": 17.639668703079224, "step": 174500}
{"episode_reward": 333.43731241960154, "episode": 1397.0, "batch_reward": 0.8918684005737305, "critic_loss": 13.042232894897461, "actor_loss": -271.33770751953125, "actor_target_entropy": -1.0, "actor_entropy": 0.6794812679290771, "alpha_loss": -0.02575661400333047, "alpha_value": 0.3200120963862675, "duration": 16.149890184402466, "step": 175000}
{"episode_reward": 193.93795127396166, "episode": 1401.0, "batch_reward": 0.8823928117752076, "critic_loss": 12.737227725982667, "actor_loss": -270.41025390625, "actor_target_entropy": -1.0, "actor_entropy": 0.6407471299171448, "alpha_loss": 0.01733548557385802, "alpha_value": 0.31839016112665497, "duration": 17.305883646011353, "step": 175500}
{"episode_reward": 142.03891243478046, "episode": 1405.0, "batch_reward": 0.9033774971961975, "critic_loss": 10.381668853759766, "actor_loss": -269.77317504882814, "actor_target_entropy": -1.0, "actor_entropy": 0.6495481014251709, "alpha_loss": 0.002391555160284042, "alpha_value": 0.31780735640806795, "duration": 18.868887901306152, "step": 176000}
{"episode_reward": 52.9579158250092, "episode": 1409.0, "batch_reward": 0.8999341011047364, "critic_loss": 11.271627807617188, "actor_loss": -271.20408935546874, "actor_target_entropy": -1.0, "actor_entropy": 0.5575293242931366, "alpha_loss": -0.006836835108697414, "alpha_value": 0.31960225863249847, "duration": 16.969465732574463, "step": 176500}
{"episode_reward": 238.27638316962867, "episode": 1413.0, "batch_reward": 0.9577252388000488, "critic_loss": 11.011591053009033, "actor_loss": -271.9924621582031, "actor_target_entropy": -1.0, "actor_entropy": 0.6155540943145752, "alpha_loss": 0.016391764767467974, "alpha_value": 0.3200922575485753, "duration": 18.550925970077515, "step": 177000}
{"episode_reward": 115.05237425515404, "episode": 1417.0, "batch_reward": 0.9067945361137391, "critic_loss": 14.338377380371094, "actor_loss": -271.55225830078126, "actor_target_entropy": -1.0, "actor_entropy": 0.6334105610847474, "alpha_loss": -0.0025996256619691847, "alpha_value": 0.3211757976074494, "duration": 15.80051302909851, "step": 177500}
{"episode_reward": 68.2853229097495, "episode": 1421.0, "batch_reward": 0.7994587540626525, "critic_loss": 9.55110569000244, "actor_loss": -272.20791015625, "actor_target_entropy": -1.0, "actor_entropy": 0.6460926413536072, "alpha_loss": -0.04050487130880356, "alpha_value": 0.32169358262322295, "duration": 23.254469394683838, "step": 178000}
{"episode_reward": 41.98000011877117, "episode": 1425.0, "batch_reward": 0.8475149273872375, "critic_loss": 12.166014671325684, "actor_loss": -272.25164794921875, "actor_target_entropy": -1.0, "actor_entropy": 0.6496124684810638, "alpha_loss": -0.01609044186770916, "alpha_value": 0.3231935918482471, "duration": 19.717535972595215, "step": 178500}
{"episode_reward": 225.39873485591076, "episode": 1429.0, "batch_reward": 0.9009061098098755, "critic_loss": 10.949787521362305, "actor_loss": -271.78529052734376, "actor_target_entropy": -1.0, "actor_entropy": 0.6732887029647827, "alpha_loss": -0.007203946076333523, "alpha_value": 0.3237566333044956, "duration": 28.353451013565063, "step": 179000}
{"episode_reward": 111.43822437851203, "episode": 1433.0, "batch_reward": 0.9774695992469787, "critic_loss": 11.631922912597656, "actor_loss": -273.3886779785156, "actor_target_entropy": -1.0, "actor_entropy": 0.6479605197906494, "alpha_loss": -0.012789942976087331, "alpha_value": 0.32537512805120966, "duration": 17.93498992919922, "step": 179500}
{"episode_reward": 91.92455055990642, "episode": 1437.0, "batch_reward": 0.8837106585502624, "critic_loss": 15.30901279449463, "actor_loss": -271.62815551757814, "actor_target_entropy": -1.0, "actor_entropy": 0.6802887082099914, "alpha_loss": -0.004060814157128334, "alpha_value": 0.32600329801951, "step": 180000}
{"duration": 40.535136699676514, "step": 180000}
{"episode_reward": 54.942587838606876, "episode": 1441.0, "batch_reward": 0.8509645104408264, "critic_loss": 10.925326347351074, "actor_loss": -272.05943603515624, "actor_target_entropy": -1.0, "actor_entropy": 0.6733741164207458, "alpha_loss": -0.013640261441469192, "alpha_value": 0.3271239811597496, "duration": 19.021292209625244, "step": 180500}
{"episode_reward": 297.15909946123156, "episode": 1445.0, "batch_reward": 0.9129586696624756, "critic_loss": 14.849462127685547, "actor_loss": -273.0130920410156, "actor_target_entropy": -1.0, "actor_entropy": 0.7038849949836731, "alpha_loss": 0.00859363079071045, "alpha_value": 0.3278928317244982, "duration": 17.923751831054688, "step": 181000}
{"episode_reward": 124.1947001373045, "episode": 1449.0, "batch_reward": 0.8999556303024292, "critic_loss": 14.043631553649902, "actor_loss": -273.48566284179685, "actor_target_entropy": -1.0, "actor_entropy": 0.7100805759429931, "alpha_loss": -0.026503944024443626, "alpha_value": 0.32960586005936954, "duration": 19.017030000686646, "step": 181500}
{"episode_reward": 161.86194651220146, "episode": 1453.0, "batch_reward": 0.8476935982704162, "critic_loss": 14.783399200439453, "actor_loss": -274.786572265625, "actor_target_entropy": -1.0, "actor_entropy": 0.651300585269928, "alpha_loss": 0.01735892556607723, "alpha_value": 0.3310249356312175, "duration": 17.961519479751587, "step": 182000}
{"episode_reward": 201.53695426464918, "episode": 1457.0, "batch_reward": 0.9048128128051758, "critic_loss": 11.576890563964843, "actor_loss": -274.55999145507815, "actor_target_entropy": -1.0, "actor_entropy": 0.7311860084533691, "alpha_loss": 0.044401776231825354, "alpha_value": 0.3290248562023851, "duration": 17.483426332473755, "step": 182500}
{"episode_reward": 193.25118274638697, "episode": 1461.0, "batch_reward": 0.869657826423645, "critic_loss": 17.810681533813476, "actor_loss": -274.6282531738281, "actor_target_entropy": -1.0, "actor_entropy": 0.6813633441925049, "alpha_loss": 0.0319626584649086, "alpha_value": 0.32375574872603974, "duration": 18.39672040939331, "step": 183000}
{"episode_reward": 222.49593739776523, "episode": 1465.0, "batch_reward": 0.8178517580032348, "critic_loss": 10.570519828796387, "actor_loss": -274.12404174804686, "actor_target_entropy": -1.0, "actor_entropy": 0.7162600636482239, "alpha_loss": 0.03442417569458485, "alpha_value": 0.319472084282566, "duration": 18.263127088546753, "step": 183500}
{"episode_reward": 247.81952362979925, "episode": 1469.0, "batch_reward": 0.8522822141647339, "critic_loss": 11.249049186706543, "actor_loss": -274.8833923339844, "actor_target_entropy": -1.0, "actor_entropy": 0.706560206413269, "alpha_loss": 0.02333889454603195, "alpha_value": 0.3181797264024149, "duration": 18.612641096115112, "step": 184000}
{"episode_reward": 211.0120895437041, "episode": 1473.0, "batch_reward": 0.8619986534118652, "critic_loss": 16.0324987411499, "actor_loss": -274.9466857910156, "actor_target_entropy": -1.0, "actor_entropy": 0.6628730416297912, "alpha_loss": 0.02364377900958061, "alpha_value": 0.3145238138251307, "duration": 17.73229670524597, "step": 184500}
{"episode_reward": 159.51536282790784, "episode": 1477.0, "batch_reward": 0.8480901122093201, "critic_loss": 12.788664054870605, "actor_loss": -274.56333618164064, "actor_target_entropy": -1.0, "actor_entropy": 0.7322093725204468, "alpha_loss": 0.038062702119350436, "alpha_value": 0.31121562291066474, "duration": 19.973044872283936, "step": 185000}
{"episode_reward": 217.21647993896485, "episode": 1481.0, "batch_reward": 0.8703720211982727, "critic_loss": 12.899928283691406, "actor_loss": -274.550927734375, "actor_target_entropy": -1.0, "actor_entropy": 0.6819071531295776, "alpha_loss": 0.02391658127307892, "alpha_value": 0.30686858295229386, "duration": 17.081642389297485, "step": 185500}
{"episode_reward": 182.6043154862605, "episode": 1485.0, "batch_reward": 0.8850966930389405, "critic_loss": 11.23357696533203, "actor_loss": -274.29041748046876, "actor_target_entropy": -1.0, "actor_entropy": 0.657711410522461, "alpha_loss": 0.02282054554671049, "alpha_value": 0.3034018379008833, "duration": 31.04590129852295, "step": 186000}
{"episode_reward": 37.26107431526786, "episode": 1489.0, "batch_reward": 0.8832347750663757, "critic_loss": 16.172816467285156, "actor_loss": -273.88511352539064, "actor_target_entropy": -1.0, "actor_entropy": 0.680972957611084, "alpha_loss": -0.01810622550547123, "alpha_value": 0.30175103949130155, "duration": 18.230927228927612, "step": 186500}
{"episode_reward": 88.69958670861196, "episode": 1493.0, "batch_reward": 0.8607701897621155, "critic_loss": 14.864005661010742, "actor_loss": -274.1456604003906, "actor_target_entropy": -1.0, "actor_entropy": 0.6596102952957154, "alpha_loss": 0.012599219381809235, "alpha_value": 0.2990638422515998, "duration": 16.574524641036987, "step": 187000}
{"episode_reward": 216.50052073496354, "episode": 1497.0, "batch_reward": 0.8461459517478943, "critic_loss": 14.758909988403321, "actor_loss": -273.2901672363281, "actor_target_entropy": -1.0, "actor_entropy": 0.6603057980537415, "alpha_loss": 0.01681936364620924, "alpha_value": 0.29594149505627954, "duration": 17.917866468429565, "step": 187500}
{"episode_reward": 51.69938505260269, "episode": 1501.0, "batch_reward": 0.8727569818496704, "critic_loss": 10.501388549804688, "actor_loss": -273.3361083984375, "actor_target_entropy": -1.0, "actor_entropy": 0.7008455157279968, "alpha_loss": 0.020848407968878747, "alpha_value": 0.2939292755854818, "duration": 17.83244299888611, "step": 188000}
{"episode_reward": 53.28688211109616, "episode": 1505.0, "batch_reward": 0.901012909412384, "critic_loss": 14.324127388000488, "actor_loss": -273.44061889648435, "actor_target_entropy": -1.0, "actor_entropy": 0.6116981387138367, "alpha_loss": 0.0017403123900294303, "alpha_value": 0.29259809002968884, "duration": 17.341915130615234, "step": 188500}
{"episode_reward": 61.650943798142414, "episode": 1509.0, "batch_reward": 0.8802259087562561, "critic_loss": 14.770772743225098, "actor_loss": -273.2620422363281, "actor_target_entropy": -1.0, "actor_entropy": 0.676778769493103, "alpha_loss": -0.0009970583021640777, "alpha_value": 0.29029866347693245, "duration": 17.128785371780396, "step": 189000}
{"episode_reward": 60.887118635450065, "episode": 1513.0, "batch_reward": 0.7825215101242066, "critic_loss": 12.824534797668457, "actor_loss": -272.4499877929687, "actor_target_entropy": -1.0, "actor_entropy": 0.6667251229286194, "alpha_loss": -0.0049322333186864855, "alpha_value": 0.2876475218587603, "duration": 16.421494722366333, "step": 189500}
{"episode_reward": 102.52475260525154, "episode": 1517.0, "batch_reward": 0.8804410338401795, "critic_loss": 14.940747451782226, "actor_loss": -271.7910400390625, "actor_target_entropy": -1.0, "actor_entropy": 0.6294960379600525, "alpha_loss": -0.00841305498033762, "alpha_value": 0.2855761638614508, "step": 190000}
{"duration": 35.01374793052673, "step": 190000}
{"episode_reward": 120.45057460082998, "episode": 1521.0, "batch_reward": 0.8518511772155761, "critic_loss": 12.007929229736328, "actor_loss": -272.3216186523438, "actor_target_entropy": -1.0, "actor_entropy": 0.5900108098983765, "alpha_loss": -0.013544615358114243, "alpha_value": 0.28472554799643346, "duration": 14.887834072113037, "step": 190500}
{"episode_reward": 177.95250955365924, "episode": 1525.0, "batch_reward": 0.8330881714820861, "critic_loss": 18.452099418640138, "actor_loss": -274.4552490234375, "actor_target_entropy": -1.0, "actor_entropy": 0.608893632888794, "alpha_loss": 0.0050147630274295805, "alpha_value": 0.2851070633543254, "duration": 15.159314155578613, "step": 191000}
{"episode_reward": 51.35425132160093, "episode": 1529.0, "batch_reward": 0.8804942488670349, "critic_loss": 20.201607513427735, "actor_loss": -274.0606262207031, "actor_target_entropy": -1.0, "actor_entropy": 0.5995331764221191, "alpha_loss": 0.022910163179039954, "alpha_value": 0.2827942524695973, "duration": 16.14177393913269, "step": 191500}
{"episode_reward": 82.26644465666436, "episode": 1533.0, "batch_reward": 0.8701689839363098, "critic_loss": 13.776228332519532, "actor_loss": -273.4137451171875, "actor_target_entropy": -1.0, "actor_entropy": 0.6114834904670715, "alpha_loss": 0.016508528590202333, "alpha_value": 0.2811528880740221, "duration": 18.470678091049194, "step": 192000}
{"episode_reward": 246.49661738269148, "episode": 1537.0, "batch_reward": 0.8810227155685425, "critic_loss": 14.604183959960938, "actor_loss": -274.458935546875, "actor_target_entropy": -1.0, "actor_entropy": 0.5773246884346008, "alpha_loss": 0.02208707183599472, "alpha_value": 0.2808090536285043, "duration": 17.61160159111023, "step": 192500}
{"episode_reward": 114.77006606866905, "episode": 1541.0, "batch_reward": 0.8774556636810302, "critic_loss": 14.345970344543456, "actor_loss": -273.7676025390625, "actor_target_entropy": -1.0, "actor_entropy": 0.6626247048377991, "alpha_loss": 0.012861311435699463, "alpha_value": 0.2806009179764669, "duration": 17.506777048110962, "step": 193000}
{"episode_reward": 332.4057279051123, "episode": 1545.0, "batch_reward": 0.7969989657402039, "critic_loss": 13.357036209106445, "actor_loss": -273.48193359375, "actor_target_entropy": -1.0, "actor_entropy": 0.6311714887619019, "alpha_loss": 0.022104565985500813, "alpha_value": 0.28065984109286074, "duration": 19.547985076904297, "step": 193500}
{"episode_reward": 160.7751251656778, "episode": 1549.0, "batch_reward": 0.8500531911849976, "critic_loss": 16.691279029846193, "actor_loss": -273.8225341796875, "actor_target_entropy": -1.0, "actor_entropy": 0.6218311429023743, "alpha_loss": -0.02554237600415945, "alpha_value": 0.279357415034136, "duration": 18.81154155731201, "step": 194000}
{"episode_reward": 100.20847875375158, "episode": 1553.0, "batch_reward": 0.9086031317710876, "critic_loss": 15.25604305267334, "actor_loss": -274.6200012207031, "actor_target_entropy": -1.0, "actor_entropy": 0.6171897649765015, "alpha_loss": 0.012262457609176635, "alpha_value": 0.27843002443356657, "duration": 18.066024780273438, "step": 194500}
{"episode_reward": 197.76628949994617, "episode": 1557.0, "batch_reward": 0.8745517253875732, "critic_loss": 17.58650646209717, "actor_loss": -274.3034912109375, "actor_target_entropy": -1.0, "actor_entropy": 0.5773413598537445, "alpha_loss": -0.0023082166910171507, "alpha_value": 0.2758439102987799, "duration": 17.373286247253418, "step": 195000}
{"episode_reward": 278.90646820575813, "episode": 1561.0, "batch_reward": 0.8633564591407776, "critic_loss": 12.12475299835205, "actor_loss": -273.7377990722656, "actor_target_entropy": -1.0, "actor_entropy": 0.6330984473228455, "alpha_loss": 0.020882067456841468, "alpha_value": 0.2737903605224753, "duration": 19.192338228225708, "step": 195500}
{"episode_reward": 237.12494653643276, "episode": 1565.0, "batch_reward": 0.9274742245674134, "critic_loss": 14.274698257446289, "actor_loss": -273.6466796875, "actor_target_entropy": -1.0, "actor_entropy": 0.6256762325763703, "alpha_loss": 0.06592626795172692, "alpha_value": 0.2693819694347568, "duration": 17.529433012008667, "step": 196000}
{"episode_reward": 189.264869096825, "episode": 1569.0, "batch_reward": 0.9775527477264404, "critic_loss": 15.011149787902832, "actor_loss": -273.93388671875, "actor_target_entropy": -1.0, "actor_entropy": 0.5900334239006042, "alpha_loss": 0.04101669043302536, "alpha_value": 0.266819343444939, "duration": 18.357603073120117, "step": 196500}
{"episode_reward": 359.7129232887351, "episode": 1573.0, "batch_reward": 0.8039472699165344, "critic_loss": 16.771019172668456, "actor_loss": -274.0264465332031, "actor_target_entropy": -1.0, "actor_entropy": 0.643596076965332, "alpha_loss": 0.0018803419545292855, "alpha_value": 0.26412661590181463, "duration": 16.9966139793396, "step": 197000}
{"episode_reward": 185.28875613175802, "episode": 1577.0, "batch_reward": 0.8880208849906921, "critic_loss": 18.753889274597167, "actor_loss": -273.24201049804685, "actor_target_entropy": -1.0, "actor_entropy": 0.585214626789093, "alpha_loss": 0.00981701174750924, "alpha_value": 0.2633537387977034, "duration": 18.474955320358276, "step": 197500}
{"episode_reward": 248.63462099691907, "episode": 1581.0, "batch_reward": 0.8916118264198303, "critic_loss": 17.223101234436037, "actor_loss": -274.3239440917969, "actor_target_entropy": -1.0, "actor_entropy": 0.5631164193153382, "alpha_loss": 0.019827972538769244, "alpha_value": 0.26204637495520433, "duration": 16.627986192703247, "step": 198000}
{"episode_reward": 344.42409889678277, "episode": 1585.0, "batch_reward": 1.0070645809173584, "critic_loss": 19.047261810302736, "actor_loss": -273.4225219726562, "actor_target_entropy": -1.0, "actor_entropy": 0.5445281028747558, "alpha_loss": -0.016820512898266315, "alpha_value": 0.2592336882620157, "duration": 16.91738200187683, "step": 198500}
{"episode_reward": 347.4761745001838, "episode": 1589.0, "batch_reward": 0.9965255737304688, "critic_loss": 18.431897735595705, "actor_loss": -273.79694213867185, "actor_target_entropy": -1.0, "actor_entropy": 0.5625332832336426, "alpha_loss": 0.004596426896750927, "alpha_value": 0.2560552334821093, "duration": 19.845090866088867, "step": 199000}
{"episode_reward": 207.892595359771, "episode": 1593.0, "batch_reward": 1.0226284503936767, "critic_loss": 17.277973175048828, "actor_loss": -273.5568359375, "actor_target_entropy": -1.0, "actor_entropy": 0.5356557607650757, "alpha_loss": 0.028443592973053454, "alpha_value": 0.2519141859640718, "duration": 18.487624406814575, "step": 199500}
